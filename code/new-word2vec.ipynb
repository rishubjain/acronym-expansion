{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv, re, string, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "remove_after = r' as in | refers to | etc.| also written | also known | e\\.g\\.|; |–|—| that is | that is,'\n",
    "split_by = r'<br\\/>| \\/ |\\n| \\\\ | or '\n",
    "acr_punc  = '!\"\\',.:;<=>?`#%()[]{}'\n",
    "note_punc = '!\"\\',.:;<=>?`#%()[]{}'\n",
    "peroid = r'\\.\\s+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishubj/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>2151-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175</td>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>2118-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>2119-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>2124-08-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>2162-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
       "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
       "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
       "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
       "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1  Discharge summary      Report   NaN      NaN   \n",
       "2  Discharge summary      Report   NaN      NaN   \n",
       "3  Discharge summary      Report   NaN      NaN   \n",
       "4  Discharge summary      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
       "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
       "2  Admission Date:  [**2119-5-4**]              D...  \n",
       "3  Admission Date:  [**2124-7-21**]              ...  \n",
       "4  Admission Date:  [**2162-3-3**]              D...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfile='/home/rishubj/text/MIMIC-data/NOTEEVENTS.csv'\n",
    "# chunksize = 10 ** 8\n",
    "chunk = pd.read_csv(dfile)\n",
    "chunk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk.to_csv('/home/rishubj/text/MIMIC-data/chunk0NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Admission Date:  [**2119-5-4**]              Discharge Date:   [**2119-5-25**]\\n\\n\\nService: CARDIOTHORACIC\\n\\nAllergies:\\nAmlodipine\\n\\nAttending:[**Last Name (NamePattern1) 1561**]\\nChief Complaint:\\n81 yo F smoker w/ COPD, severe TBM, s/p tracheobronchoplasty [**5-5**]\\ns/p perc trach [**5-13**]\\n\\nMajor Surgical or Invasive Procedure:\\nbronchoscopy 3/31,4/2,3,[**6-12**], [**5-17**], [**5-19**]\\ns/p trachealplasty [**5-5**]\\npercutaneous tracheostomy [**5-13**] after failed extubation\\ndown size trach on [**5-25**] to size 6 cuffless\\n\\n\\nHistory of Present Illness:\\nThis 81 year old woman has a history of COPD. Over the past five\\n\\nyears she has had progressive difficulties with her breathing.\\nIn\\n[**2118-6-4**] she was admitted to [**Hospital1 18**] for respiratory failure\\ndue\\nto a COPD exacerbation. Due to persistent hypoxemia, she\\nrequired\\nintubation and a eventual bronchoscopy on [**2118-6-9**] revealed marked\\n\\nnarrowing of the airways on expiration consistent with\\ntracheomalacia.\\nShe subsequently underwent placement of two\\nsilicone stents, one in the left main stem and one in the\\ntrachea. During the admission the patient had complaints of\\nchest\\npain and ruled out for an MI. She was subsequently discharged to\\n\\n[**Hospital1 **] for physical and pulmonary rehab. Repeat bronchoscopy\\non\\n[**2118-8-1**] revealed granulation tissue at the distal right lateral\\nwall of the tracheal stent. There was significant malacia of the\\n\\nperipheral and central airways with complete collapse of the\\nairways on coughing and forced expiration. Small nodules were\\nalso noted on the vocal cords. She has noticed improvement in\\nher\\nrespiratory status, but most recently has been in discussion\\nwith Dr. [**First Name4 (NamePattern1) 951**] [**Last Name (NamePattern1) 952**] regarding possible tracheobronchial plasty\\n\\nwith mesh. Tracheal stents d/c [**2119-4-19**] in anticipation of\\nsurgery.\\nIn terms of symptoms, she describes many years of intermittent\\nchest pain that she describes as left sided and occurring at any\\n\\ntime. Currently, she notices it about three times a week, and\\nstates that it seems to resolve after three nitroglycerin.\\nShe currently is dependent on oxygen and wears 1.5-2 liters\\naround the clock. She has frequent coughing and brings up \"dark\\nsputum\".\\n\\n\\n\\nPast Medical History:\\nCOPD flare [**6-7**] s/p intubation, s/p distal tracheal to Left Main\\nStem stents placed [**2118-6-9**]. Stents d/c\\'d [**2119-4-19**], CAD w/ atypical\\nangina (LAD 30%, RCA 30%, EF 63%), ^chol, hypothyroidism, htn,\\nhiatal hernia, lacunar CVA, s/p ped struck -> head injury & rib\\nfx, depression\\nPMH:\\nCOPD, s/p admit [**6-7**] for exacerbation requiring intubation\\ntracheobronchomalacia, s/p bronchial stenting\\nLarge hiatal hernia\\nLacunar CVA\\nHypothyroidism by records in CCC, although patient denies and is\\n\\nnot taking any medication\\nDepression\\nMVA, s/p head injury approximately 10 years ago\\nHypertension\\nHysterectomy\\n\\n\\nSocial History:\\nSocial History: The patient is married and worked as a clinical\\npsychologist. Her husband is a pediatric neurologist at\\n[**Hospital3 **]. They have several children, one of which is\\n\\na nurse.\\n\\n\\nFamily History:\\nFamily History: (+) FHx CAD; Father with an MI in his 40\\'s, died\\n\\nof a CVA at age 59\\n\\n\\nPhysical Exam:\\nAdmit H+P\\nGeneral-lovely 81 yr old feamle in NAD.\\nNeuro- intermittently anxious, MAE, PERRLA, L eye ptosis,\\nsymetrical smile, gossly intact.\\nHEENT-PERRLA, sclera anicteric, pharynx- no exud or erythema\\nResp-clear upper, diffuse ronchi, intermit exp wheezes\\nCor- RRR, No M, R, G\\nAbd- soft, NT, ND, no masses. Slight protrusion at area of\\nhiatal hernia\\nExt- no edema or clubbing\\n\\nBrief Hospital Course:\\n82 y/o female admitted [**2119-5-4**] for consideration of\\ntracheoplasty.\\nBronchoscopy done [**5-4**] confirming severe TBM. Underwent\\ntracheoplasty [**5-5**], complicated by resp failure d/t mucous\\nplugging, hypoxia requiring re-intubation resulting in prolonged\\nICU and hospital course. Also developed right upper extrem DVT\\nfrom mid line.\\n\\nPain- Epidural accidently d/c\\'d POD#1, pt briefly used dilaudid\\nPCA intermittently w/ fair pain control. Pt required\\nre-intubation for resp failure d/t secretions and PCA d/c at\\nthat time. Propofol for sedation while intubated. Sedation d/c\\'d\\n[**5-12**] for weaning trial w/ ETT- failed trial. Trach [**5-13**]-weaning\\nefforts as below. Minimal c/o pain since [**5-13**]. Presently pain\\nfree.\\n\\nNeuro- Initially intact- post op aggitation, inhibiting weaning\\nefforts [**5-16**]. Psych eval [**5-18**]-Started on zyprexa and ativan w/\\nimprovement in anxiety. Presently A+Ox3- cooperative and lovely.\\n\\nResp- Extubated POD#2 then required re-intub  [**5-7**] for hypoxia\\nd/t poor cough and mucous plugging. SIMV/PS alt w/CMV at night\\nx4-5d, with CPAP attempts during day.\\nBronchoscopy qd [**Date range (1) 1813**] for secretion management. Bronch [**5-9**]\\nrevealed swollen epiglottis, bronch [**5-10**] - good leak w/ ETT cuff\\ndeflated. Bronch [**5-13**] for eval/trach placement. Last bronch [**5-19**]\\nw/ min secretions present, sputum sent.\\n[**5-13**] perc trach done(#8 Portex- cuffed low pressure maintained to\\npreserve tracheoplasty site). [**5-13**] CPAP15/peep5 initiated post\\ntrach placement. Weaning ongoing.  [**Date range (1) 1814**]- Aggressive weaning\\nw/ increasing episodes of CPAP, progressing to Trach Mask.\\n[**2033-5-20**]-Trach mask overnight w/ no episodes of SOB, or\\nhemodynamic instability. Trach changed to #6 portex- capped and\\n[**Last Name (un) 1815**] well x48hrs on 2LNP. productive cough. Aggressive PT as\\nwell w/ OOB > chair [**Hospital1 **]-tid to total 4-6hr qd. Ambulation\\n~100-120 ft [**5-22**] w/ PT assist.\\n\\nID- Vancomycin started post-op for graft prophylaxis. Fever\\nspike [**2119-5-8**] w/ BAl & sputum sent> + MRSA. Vanco cont to [**4-7**]\\nweeks post trachealplasty. Fever low grade [**5-12**], [**5-15**]> cultured-\\nno new results. [**5-19**]- WBC 20.8 .\\n\\nCardiac-Hypertension controlled w/ hydralazine IV, then d/c and\\ncont controlled. HR 65-75 NSR. Avoiding B Blockers. Lasix 20mg\\nIV qd.\\n[**5-15**]- RUE redness and swelling at site of midline, RUE DVT by\\nultrasound, midline d/c; heparin gtt started and therapeutic\\nrange monitored. [**5-22**]  changed to Lovenox sq [**Hospital1 **]. Coags in good\\ncontrol [**5-23**] (48.2/13.8/1.2)\\nAccess- R midline placed [**2119-5-9**] for access- clotted [**2119-5-15**] and\\nd/c\\'d.  RUE redness and swelling and DVT via ultrasound. [**5-15**]- L\\nbrachial PICC line placed- TPN resumed.\\n\\nGI-Large hiatal hernia- unable to place enteral feeding tube at\\nbedside or underfluoro. Re-attempt [**5-17**] by EGD doboff tube\\nplaced distal esophagus, dislodged in 12hours and removed.\\n\\nNutrition- PPN/TPN initiated [**2119-5-8**]- [**2119-5-25**]. PICC placed\\n[**2119-5-15**]. Speech and Swallow eval [**5-22**]- rec change trach form #8\\nto #6 Portex to allow improved epiglotis and oropharyngeal\\nmovement to assist w/ swallowing. Then re-eval.  Trach changed\\n[**5-23**] to #6 cuffless portex trach. Passed repeat swallow eval and\\n[**Last Name (un) 1815**] diet of regular solids w/ thin liquids- CHIN TUCK to\\nswallow thin liquids. Give meds whole w/ apple sauce. WOULD\\nRECOMMEND repeat video swallow eval in [**8-17**] days to possibly\\neliminate chin tuck- see page 3 referral.\\n\\nEndo- Hypothyroid, maintained on levoxyl.\\n\\nMuscu/Skel- OOB> chair 4-6hours/day, PT consulting.\\n\\n\\nMedications on Admission:\\nadvair 250/50\", atrovent, imdur 60\\', lasix 40\\', lexapro 20\\',\\nlipitor 10\\', prilosec 20\\', mucinex 600\", synthroid 75\\', detrol\\nLA 4\\', ambien 5\\', trazadone 75\\', melatonin prn\\n\\nDischarge Medications:\\n1. Albuterol Sulfate 0.083 % Solution Sig: One (1)  Inhalation\\nQ6H (every 6 hours) as needed for wheezing.\\n2. Ipratropium Bromide 0.02 % Solution Sig: One (1)  Inhalation\\nQ6H (every 6 hours) as needed for wheezing.\\n3. Fluticasone-Salmeterol 250-50 mcg/Dose Disk with Device Sig:\\nOne (1) Disk with Device Inhalation [**Hospital1 **] (2 times a day).\\n4. Albuterol 90 mcg/Actuation Aerosol Sig: 1-2 Puffs Inhalation\\nQ6H (every 6 hours) as needed.\\n5. Ipratropium Bromide 18 mcg/Actuation Aerosol Sig: Two (2)\\nPuff Inhalation QID (4 times a day).\\n6. Acetaminophen 325 mg Tablet Sig: 1-2 Tablets PO Q4-6H (every\\n4 to 6 hours) as needed.\\n7. Sodium Chloride 0.65 % Aerosol, Spray Sig: [**2-5**] Sprays Nasal\\nQID (4 times a day) as needed.\\n8. Camphor-Menthol 0.5-0.5 % Lotion Sig: One (1) Appl Topical\\nTID (3 times a day) as needed.\\n9. Enoxaparin Sodium 60 mg/0.6mL Syringe Sig: One (1)\\nSubcutaneous Q12H (every 12 hours).\\n10. Trazodone HCl 50 mg Tablet Sig: 1.5 Tablets PO HS (at\\nbedtime) as needed.\\n11. Escitalopram Oxalate 10 mg Tablet Sig: Two (2) Tablet PO\\nDAILY (Daily).\\n12. Nystatin 100,000 unit/g Cream Sig: One (1) Appl Topical  [**Hospital1 **]\\n(2 times a day).\\n13. Pantoprazole Sodium 40 mg Tablet, Delayed Release (E.C.)\\nSig: One (1) Tablet, Delayed Release (E.C.) PO Q24H (every 24\\nhours).\\n14. Tolterodine Tartrate 2 mg Tablet Sig: One (1) Tablet PO BID\\n(2 times a day).\\n15. Levothyroxine Sodium 75 mcg Tablet Sig: One (1) Tablet PO\\nDAILY (Daily).\\n16. Heparin Lock Flush (Porcine) 100 unit/mL Syringe Sig: One\\n(1) ML Intravenous  DAILY (Daily) as needed.\\n\\n\\nDischarge Disposition:\\nExtended Care\\n\\nFacility:\\n[**Hospital3 7**] & Rehab Center - [**Hospital1 8**]\\n\\nDischarge Diagnosis:\\nCOPD, Coronary Artery Disease/atypical angina (LAD 30%, RCA 30%,\\nEF 63%), hypercholesterolemia, hypothyroidism, Hypertension,\\nhiatal hernia, Cerebral Vascular Accident,s/p Motor Vehicle\\nColision-> head injury & rib fracture.\\nTBM- s/p tracheoplasty.\\n\\n\\nDischarge Condition:\\ngood\\n\\nDischarge Instructions:\\nplease update Dr.[**Name (NI) 1816**] [**Telephone/Fax (1) 170**] office for:  fever,\\nshortness of breath, chest pain , productive cough or if you\\nhave any questions or concerns.\\n\\n\\nCompleted by:[**2119-5-25**]',\n",
       " ['Admission',\n",
       "  'Date:',\n",
       "  '[**2151-7-16**]',\n",
       "  'Discharge',\n",
       "  'Date:',\n",
       "  '[**2151-8-4**]',\n",
       "  'Service:',\n",
       "  'ADDENDUM:',\n",
       "  'RADIOLOGIC',\n",
       "  'STUDIES:',\n",
       "  'Radiologic',\n",
       "  'studies',\n",
       "  'also',\n",
       "  'included',\n",
       "  'a',\n",
       "  'chest',\n",
       "  'CT,',\n",
       "  'which',\n",
       "  'confirmed',\n",
       "  'cavitary',\n",
       "  'lesions',\n",
       "  'in',\n",
       "  'the',\n",
       "  'left',\n",
       "  'lung',\n",
       "  'apex',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'infectious',\n",
       "  'process/tuberculosis.',\n",
       "  'This',\n",
       "  'also',\n",
       "  'moderate-sized',\n",
       "  'left',\n",
       "  'pleural',\n",
       "  'effusion.',\n",
       "  'HEAD',\n",
       "  'CT:',\n",
       "  'Head',\n",
       "  'CT',\n",
       "  'showed',\n",
       "  'no',\n",
       "  'intracranial',\n",
       "  'hemorrhage',\n",
       "  'or',\n",
       "  'mass',\n",
       "  'effect,',\n",
       "  'but',\n",
       "  'old',\n",
       "  'infarction',\n",
       "  'consistent',\n",
       "  'with',\n",
       "  'past',\n",
       "  'medical',\n",
       "  'history.',\n",
       "  'ABDOMINAL',\n",
       "  'CT:',\n",
       "  'Abdominal',\n",
       "  'CT',\n",
       "  'showed',\n",
       "  'lesions',\n",
       "  'of',\n",
       "  'T10',\n",
       "  'and',\n",
       "  'sacrum',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'secondary',\n",
       "  'to',\n",
       "  'osteoporosis.',\n",
       "  'These',\n",
       "  'can',\n",
       "  'be',\n",
       "  'followed',\n",
       "  'by',\n",
       "  'repeat',\n",
       "  'imaging',\n",
       "  'as',\n",
       "  'an',\n",
       "  'outpatient.',\n",
       "  '[**First',\n",
       "  'Name8',\n",
       "  '(NamePattern2)',\n",
       "  '**]',\n",
       "  '[**First',\n",
       "  'Name4',\n",
       "  '(NamePattern1)',\n",
       "  '1775**]',\n",
       "  '[**Last',\n",
       "  'Name',\n",
       "  '(NamePattern1)',\n",
       "  '**],',\n",
       "  'M.D.',\n",
       "  '[**MD',\n",
       "  'Number(1)',\n",
       "  '1776**]',\n",
       "  'Dictated',\n",
       "  'By:[**Hospital',\n",
       "  '1807**]',\n",
       "  'MEDQUIST36',\n",
       "  'D:',\n",
       "  '[**2151-8-5**]',\n",
       "  '12:11',\n",
       "  'T:',\n",
       "  '[**2151-8-5**]',\n",
       "  '12:21',\n",
       "  'JOB#:',\n",
       "  '[**Job',\n",
       "  'Number',\n",
       "  '1808**]'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.head()['TEXT'][2], chunk.head()['TEXT'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('acros.pickle', 'rb') as handle:\n",
    "    acro_dct = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    return ' '.join(re.sub(r'\\b\\d+\\b', ' number_phrase ',\n",
    "        re.sub(r'[\\[]\\*\\*.*?\\*\\*[\\]]', ' redacted_phrase ', line).translate(None, note_punc).lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishubj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "chunk['TEXT'].apply(clean_line).to_csv(\"/home/rishubj/text/MIMIC-data/cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in acro_dct.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dict = {}\n",
    "for k,v in acro_dct.items():\n",
    "    for vv in v:\n",
    "        if vv not in inverted_dict:\n",
    "            inverted_dict[vv] = []\n",
    "        inverted_dict[vv].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'help'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b026ab0b5634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macro_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'help'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'help'"
     ]
    }
   ],
   "source": [
    "acro_dct['help']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_dict['fever of unknown origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(flat_list).to_csv('test.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list), len(set(flat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['zinc deficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter(flat_list)\n",
    "p=sorted(c.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=100\n",
    "p[i], c[p[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/rishubj/text/code/test.csv', 'rb') as handle:\n",
    "    l= (handle.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.head()['TEXT'][:30].apply(clean_line)[0]==l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o=set()\n",
    "for line in chunk.head()['TEXT'][:30]:\n",
    "    l= (re.sub(r'\\b\\d+\\b', ' number_phrase ',\n",
    "        re.sub(r'[\\[]\\*\\*.*?\\*\\*[\\]]', ' redacted_phrase ', line).translate(None, note_punc).lower()).split())\n",
    "    for i in l:\n",
    "        if i in acro_dct:\n",
    "            o.add(i)\n",
    "for i in sorted(o):\n",
    "    print i, acro_dct[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([j  for j in acro_dct.values() if len(j)>1]), len(acro_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/rishubj/text/MIMIC-data/smallestNOTES.csv') as f:\n",
    "#     l = [x.strip() for x in f.readlines()] #tf.compat.as_str(f.read()).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile='/home/rishubj/text/MIMIC-data/cleaned.csv'\n",
    "cleaned = pd.read_csv(dfile, header=None).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishubj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Admission Date:  [**2151-7-16**]       Discharge Date:  [**2151-8-4**]\\n\\n\\nService:\\nADDENDUM:\\n\\nRADIOLOGIC STUDIES:  Radiologic studies also included a chest\\nCT, which confirmed cavitary lesions in the left lung apex\\nconsistent with infectious process/tuberculosis.  This also\\nmoderate-sized left pleural effusion.\\n\\nHEAD CT:  Head CT showed no intracranial hemorrhage or mass\\neffect, but old infarction consistent with past medical\\nhistory.\\n\\nABDOMINAL CT:  Abdominal CT showed lesions of\\nT10 and sacrum most likely secondary to osteoporosis. These can\\nbe followed by repeat imaging as an outpatient.\\n\\n\\n\\n                            [**First Name8 (NamePattern2) **] [**First Name4 (NamePattern1) 1775**] [**Last Name (NamePattern1) **], M.D.  [**MD Number(1) 1776**]\\n\\nDictated By:[**Hospital 1807**]\\nMEDQUIST36\\n\\nD:  [**2151-8-5**]  12:11\\nT:  [**2151-8-5**]  12:21\\nJOB#:  [**Job Number 1808**]\\n',\n",
       " 'admission date redacted_phrase discharge date redacted_phrase service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process/tuberculosis this also moderate-sized left pleural effusion head ct head ct showed no intracranial hemorrhage or mass effect but old infarction consistent with past medical history abdominal ct abdominal ct showed lesions of t10 and sacrum most likely secondary to osteoporosis these can be followed by repeat imaging as an outpatient redacted_phrase redacted_phrase redacted_phrase md redacted_phrase dictated by redacted_phrase medquist36 d redacted_phrase number_phrase t redacted_phrase number_phrase job redacted_phrase')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['TEXT'][0], cleaned.ix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admission date redacted_phrase discharge date redacted_phrase service addendum radiologic studies radiologic studies also included a chest ct which confirmed cavitary lesions in the left lung apex consistent with infectious process/tuberculosis this also moderate-sized left pleural effusion head ct head ct showed no intracranial hemorrhage or mass effect but old infarction consistent with past medical history abdominal ct abdominal ct showed lesions of t10 and sacrum most likely secondary to osteoporosis these can be followed by repeat imaging as an outpatient redacted_phrase redacted_phrase redacted_phrase md redacted_phrase dictated by redacted_phrase medquist36 d redacted_phrase number_phrase t redacted_phrase number_phrase job redacted_phrase\n"
     ]
    }
   ],
   "source": [
    "for sent in cleaned.iloc[:,0]:\n",
    "    print (sent)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words = [word for word in sent.split() for sent in cleaned.iloc[:,0] if len(word)>0]\n",
    "all_words = [word for sent in cleaned.iloc[:,0] for word in sent.split() if len(word)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512392754"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishubj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0    normal sinus rhythm q waves in leads v1-v4 sug...\n",
       " Name: 104287, dtype: object, '\\n\\n\\n', '')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.iloc[104286], chunk.ix[104286, \"TEXT\"], clean_line(chunk.ix[104286, \"TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104284</th>\n",
       "      <td>sinus rhythm normal tracing compared to the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104285</th>\n",
       "      <td>sinus rhythm with borderline sinus tachycardia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104287</th>\n",
       "      <td>normal sinus rhythm q waves in leads v1-v4 sug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "104284  sinus rhythm normal tracing compared to the pr...\n",
       "104285  sinus rhythm with borderline sinus tachycardia...\n",
       "104287  normal sinus rhythm q waves in leads v1-v4 sug..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.iloc[104284:104287]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, line in enumerate(cleaned.iloc[:,0]):\n",
    "    if type(line)!=str:\n",
    "        print (i,line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_dataset(all_words, lines, n_words):\n",
    "#     \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "#     count = [['UNK', -1]]\n",
    "#     count.extend(collections.Counter(all_words).most_common(n_words - 1))\n",
    "#     dictionary = dict()\n",
    "#     for word, _ in count:\n",
    "#         dictionary[word] = len(dictionary)\n",
    "#     print (\"made vocabulary\")\n",
    "#     data = list()\n",
    "#     unk_count = 0\n",
    "#     for line in lines:\n",
    "#         line_data=[]\n",
    "#         for word in line.split():\n",
    "#             if len(word)>0:\n",
    "#                 if word in dictionary:\n",
    "#                     index = dictionary[word]\n",
    "#                 else:\n",
    "#                     index = 0  # dictionary['UNK']\n",
    "#                     unk_count += 1\n",
    "#                 line_data.append(index)\n",
    "#         if len(line_data)>0:\n",
    "#             data.append(line_data)\n",
    "#     count[0][1] = unk_count\n",
    "#     reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "#     return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def build_dataset(all_words, lines, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(all_words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    print (\"made vocabulary\")\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in all_words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 10000\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(all_words, cleaned.iloc[:,0], vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admission',\n",
       " 'date',\n",
       " 'redacted_phrase',\n",
       " 'discharge',\n",
       " 'date',\n",
       " 'redacted_phrase',\n",
       " 'service',\n",
       " 'addendum',\n",
       " 'radiologic',\n",
       " 'studies',\n",
       " 'radiologic',\n",
       " 'studies',\n",
       " 'also',\n",
       " 'included',\n",
       " 'a',\n",
       " 'chest',\n",
       " 'ct',\n",
       " 'which',\n",
       " 'confirmed',\n",
       " 'cavitary',\n",
       " 'lesions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'left',\n",
       " 'lung',\n",
       " 'apex',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'infectious',\n",
       " 'process/tuberculosis',\n",
       " 'this',\n",
       " 'also',\n",
       " 'moderate-sized',\n",
       " 'left',\n",
       " 'pleural',\n",
       " 'effusion',\n",
       " 'head',\n",
       " 'ct',\n",
       " 'head',\n",
       " 'ct',\n",
       " 'showed',\n",
       " 'no',\n",
       " 'intracranial',\n",
       " 'hemorrhage',\n",
       " 'or',\n",
       " 'mass',\n",
       " 'effect',\n",
       " 'but',\n",
       " 'old',\n",
       " 'infarction',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'past',\n",
       " 'medical',\n",
       " 'history',\n",
       " 'abdominal',\n",
       " 'ct',\n",
       " 'abdominal',\n",
       " 'ct',\n",
       " 'showed',\n",
       " 'lesions',\n",
       " 'of',\n",
       " 't10',\n",
       " 'and',\n",
       " 'sacrum',\n",
       " 'most',\n",
       " 'likely',\n",
       " 'secondary',\n",
       " 'to',\n",
       " 'osteoporosis',\n",
       " 'these',\n",
       " 'can',\n",
       " 'be',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'repeat',\n",
       " 'imaging',\n",
       " 'as',\n",
       " 'an',\n",
       " 'outpatient',\n",
       " 'redacted_phrase',\n",
       " 'redacted_phrase',\n",
       " 'redacted_phrase',\n",
       " 'md',\n",
       " 'redacted_phrase',\n",
       " 'dictated',\n",
       " 'by',\n",
       " 'redacted_phrase',\n",
       " 'medquist36',\n",
       " 'd',\n",
       " 'redacted_phrase',\n",
       " 'number_phrase',\n",
       " 't',\n",
       " 'redacted_phrase',\n",
       " 'number_phrase',\n",
       " 'job',\n",
       " 'redacted_phrase',\n",
       " 'admission',\n",
       " 'date',\n",
       " 'redacted_phrase',\n",
       " 'discharge',\n",
       " 'date',\n",
       " 'redacted_phrase',\n",
       " 'date',\n",
       " 'of',\n",
       " 'birth',\n",
       " 'sex',\n",
       " 'f',\n",
       " 'service',\n",
       " 'micu',\n",
       " 'and',\n",
       " 'then',\n",
       " 'to',\n",
       " 'redacted_phrase',\n",
       " 'medicine',\n",
       " 'history',\n",
       " 'of',\n",
       " 'present',\n",
       " 'illness',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'number_phrase',\n",
       " '-year-old',\n",
       " 'female',\n",
       " 'with',\n",
       " 'a',\n",
       " 'history',\n",
       " 'of',\n",
       " 'emphysema',\n",
       " 'not',\n",
       " 'on',\n",
       " 'home',\n",
       " 'o2',\n",
       " 'who',\n",
       " 'presents',\n",
       " 'with',\n",
       " 'three',\n",
       " 'days',\n",
       " 'of',\n",
       " 'shortness',\n",
       " 'of',\n",
       " 'breath',\n",
       " 'thought',\n",
       " 'by',\n",
       " 'her',\n",
       " 'primary',\n",
       " 'care',\n",
       " 'doctor',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'copd',\n",
       " 'flare',\n",
       " 'two',\n",
       " 'days',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'admission',\n",
       " 'she',\n",
       " 'was',\n",
       " 'started',\n",
       " 'on',\n",
       " 'a',\n",
       " 'prednisone',\n",
       " 'taper',\n",
       " 'and',\n",
       " 'one',\n",
       " 'day',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'admission',\n",
       " 'she',\n",
       " 'required',\n",
       " 'oxygen',\n",
       " 'at',\n",
       " 'home',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'maintain',\n",
       " 'oxygen',\n",
       " 'saturation',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'number_phrase',\n",
       " 'she',\n",
       " 'has',\n",
       " 'also',\n",
       " 'been',\n",
       " 'on',\n",
       " 'levofloxacin',\n",
       " 'and',\n",
       " 'nebulizers',\n",
       " 'and',\n",
       " 'was',\n",
       " 'not',\n",
       " 'getting',\n",
       " 'better',\n",
       " 'and',\n",
       " 'presented',\n",
       " 'to',\n",
       " 'the',\n",
       " 'redacted_phrase',\n",
       " 'emergency',\n",
       " 'room',\n",
       " 'in',\n",
       " 'the',\n",
       " 'redacted_phrase',\n",
       " 'emergency',\n",
       " 'room',\n",
       " 'her',\n",
       " 'oxygen',\n",
       " 'saturation',\n",
       " 'was',\n",
       " 'number_phrase',\n",
       " 'on',\n",
       " 'cpap',\n",
       " 'she',\n",
       " 'was',\n",
       " 'not',\n",
       " 'able',\n",
       " 'to',\n",
       " 'be',\n",
       " 'weaned',\n",
       " 'off',\n",
       " 'of',\n",
       " 'this',\n",
       " 'despite',\n",
       " 'nebulizer',\n",
       " 'treatment',\n",
       " 'and',\n",
       " 'solu-medrol',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'iv',\n",
       " 'x2',\n",
       " 'review',\n",
       " 'of',\n",
       " 'systems',\n",
       " 'is',\n",
       " 'negative',\n",
       " 'for',\n",
       " 'the',\n",
       " 'following',\n",
       " 'fevers',\n",
       " 'chills',\n",
       " 'nausea',\n",
       " 'vomiting',\n",
       " 'night',\n",
       " 'sweats',\n",
       " 'change',\n",
       " 'in',\n",
       " 'weight',\n",
       " 'gastrointestinal',\n",
       " 'complaints',\n",
       " 'neurologic',\n",
       " 'changes',\n",
       " 'rashes',\n",
       " 'palpitations',\n",
       " 'orthopnea',\n",
       " 'is',\n",
       " 'positive',\n",
       " 'for',\n",
       " 'the',\n",
       " 'following',\n",
       " 'chest',\n",
       " 'pressure',\n",
       " 'occasionally',\n",
       " 'with',\n",
       " 'shortness',\n",
       " 'of',\n",
       " 'breath',\n",
       " 'with',\n",
       " 'exertion',\n",
       " 'some',\n",
       " 'shortness',\n",
       " 'of',\n",
       " 'breath',\n",
       " 'that',\n",
       " 'is',\n",
       " 'positionally',\n",
       " 'related',\n",
       " 'but',\n",
       " 'is',\n",
       " 'improved',\n",
       " 'with',\n",
       " 'nebulizer',\n",
       " 'treatment',\n",
       " 'past',\n",
       " 'medical',\n",
       " 'history',\n",
       " 'number_phrase',\n",
       " 'copd',\n",
       " 'last',\n",
       " 'pulmonary',\n",
       " 'function',\n",
       " 'tests',\n",
       " 'in',\n",
       " 'redacted_phrase',\n",
       " 'demonstrated',\n",
       " 'a',\n",
       " 'fvc',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'of',\n",
       " 'predicted',\n",
       " 'a',\n",
       " 'fev1',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'of',\n",
       " 'predicted',\n",
       " 'a',\n",
       " 'mmf',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'of',\n",
       " 'predicted',\n",
       " 'and',\n",
       " 'a',\n",
       " 'fev1fvc',\n",
       " 'ratio',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'of',\n",
       " 'predicted',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'improve',\n",
       " 'with',\n",
       " 'bronchodilator',\n",
       " 'treatment',\n",
       " 'the',\n",
       " 'fvc',\n",
       " 'however',\n",
       " 'does',\n",
       " 'significantly',\n",
       " 'improve',\n",
       " 'with',\n",
       " 'bronchodilator',\n",
       " 'treatment',\n",
       " 'consistent',\n",
       " 'with',\n",
       " 'her',\n",
       " 'known',\n",
       " 'reversible',\n",
       " 'air',\n",
       " 'flow',\n",
       " 'obstruction',\n",
       " 'in',\n",
       " 'addition',\n",
       " 'to',\n",
       " 'an',\n",
       " 'underlying',\n",
       " 'restrictive',\n",
       " 'ventilatory',\n",
       " 'defect',\n",
       " 'the',\n",
       " 'patient',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'on',\n",
       " 'home',\n",
       " 'oxygen',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'this',\n",
       " 'recent',\n",
       " 'episode',\n",
       " 'she',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'on',\n",
       " 'steroid',\n",
       " 'taper',\n",
       " 'or',\n",
       " 'been',\n",
       " 'intubated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'number_phrase',\n",
       " 'lacunar',\n",
       " 'cva',\n",
       " 'mri',\n",
       " 'of',\n",
       " 'the',\n",
       " 'head',\n",
       " 'in',\n",
       " 'redacted_phrase',\n",
       " 'demonstrates',\n",
       " 'mild',\n",
       " 'degree',\n",
       " 'of',\n",
       " 'multiple',\n",
       " 'small',\n",
       " 'foci',\n",
       " 'of',\n",
       " 'high',\n",
       " 't2',\n",
       " 'signal',\n",
       " 'within',\n",
       " 'the',\n",
       " 'white',\n",
       " 'matter',\n",
       " 'of',\n",
       " 'both',\n",
       " 'cerebral',\n",
       " 'hemispheres',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'pons',\n",
       " 'in',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'region',\n",
       " 'predominantly',\n",
       " 'to',\n",
       " 'the',\n",
       " 'right',\n",
       " 'of',\n",
       " 'midline',\n",
       " 'the',\n",
       " 'abnormalities',\n",
       " 'while',\n",
       " 'nonspecific',\n",
       " 'in',\n",
       " 'etiology',\n",
       " 'are',\n",
       " 'most',\n",
       " 'likely',\n",
       " 'secondary',\n",
       " 'to',\n",
       " 'chronic',\n",
       " 'microvascular',\n",
       " 'infarction',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'mass',\n",
       " 'lesion',\n",
       " 'shift',\n",
       " 'of',\n",
       " 'the',\n",
       " 'normal',\n",
       " 'midline',\n",
       " 'strictures',\n",
       " 'or',\n",
       " 'hydrocephalus',\n",
       " 'the',\n",
       " 'major',\n",
       " 'vascular',\n",
       " 'flow',\n",
       " 'patterns',\n",
       " 'are',\n",
       " 'preserved',\n",
       " 'there',\n",
       " 'is',\n",
       " 'moderate',\n",
       " 'right',\n",
       " 'maxillary',\n",
       " 'moderate',\n",
       " 'bilateral',\n",
       " 'ethmoid',\n",
       " 'mild',\n",
       " 'left',\n",
       " 'maxillary',\n",
       " 'minimal',\n",
       " 'right',\n",
       " 'sphenoid',\n",
       " 'and',\n",
       " 'frontal',\n",
       " 'sinus',\n",
       " 'mucosal',\n",
       " 'thickening',\n",
       " 'these',\n",
       " 'abnormalities',\n",
       " 'could',\n",
       " 'represent',\n",
       " 'an',\n",
       " 'allergic',\n",
       " 'or',\n",
       " 'some',\n",
       " 'other',\n",
       " 'type',\n",
       " 'of',\n",
       " 'inflammatory',\n",
       " 'process',\n",
       " 'additionally',\n",
       " 'noted',\n",
       " 'is',\n",
       " 'a',\n",
       " 'moderately',\n",
       " 'enlarged',\n",
       " 'subtotally',\n",
       " 'empty',\n",
       " 'sella',\n",
       " 'turcica',\n",
       " 'number_phrase',\n",
       " 'angina',\n",
       " 'most',\n",
       " 'recent',\n",
       " 'stress',\n",
       " 'test',\n",
       " 'was',\n",
       " 'in',\n",
       " 'redacted_phrase',\n",
       " 'going',\n",
       " 'for',\n",
       " 'four',\n",
       " 'minutes',\n",
       " 'with',\n",
       " 'a',\n",
       " 'rate',\n",
       " 'pressure',\n",
       " 'product',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'of',\n",
       " 'maximum',\n",
       " 'predicted',\n",
       " 'heart',\n",
       " 'rate',\n",
       " 'without',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'ischemic',\n",
       " 'ekg',\n",
       " 'changes',\n",
       " 'or',\n",
       " 'symptoms',\n",
       " 'the',\n",
       " 'imaging',\n",
       " 'portion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'study',\n",
       " 'demonstrated',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'myocardial',\n",
       " 'ischemia',\n",
       " 'and',\n",
       " 'a',\n",
       " 'calculated',\n",
       " 'ejection',\n",
       " 'fraction',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'the',\n",
       " 'patient',\n",
       " 'denies',\n",
       " 'angina',\n",
       " 'at',\n",
       " 'rest',\n",
       " 'and',\n",
       " 'gets',\n",
       " 'angina',\n",
       " 'with',\n",
       " 'walking',\n",
       " 'a',\n",
       " 'few',\n",
       " 'blocks',\n",
       " 'are',\n",
       " 'alleviated',\n",
       " 'by',\n",
       " 'sublingual',\n",
       " 'nitroglycerin',\n",
       " 'number_phrase',\n",
       " 'hypothyroidism',\n",
       " 'on',\n",
       " 'synthroid',\n",
       " 'number_phrase',\n",
       " 'depression',\n",
       " 'on',\n",
       " 'lexapro',\n",
       " 'number_phrase',\n",
       " 'motor',\n",
       " 'vehicle',\n",
       " 'accident',\n",
       " 'with',\n",
       " 'head',\n",
       " 'injury',\n",
       " 'approximately',\n",
       " 'number_phrase',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'medications',\n",
       " 'on',\n",
       " 'admission',\n",
       " 'number_phrase',\n",
       " 'hydrochlorothiazide',\n",
       " 'number_phrase',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'prednisone',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'number_phrase',\n",
       " 'levofloxacin',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'imdur',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'synthroid',\n",
       " 'number_phrase',\n",
       " 'mcg',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'pulmicort',\n",
       " 'nebulizer',\n",
       " 'bid',\n",
       " 'number_phrase',\n",
       " 'albuterol',\n",
       " 'nebulizer',\n",
       " 'q4',\n",
       " 'prn',\n",
       " 'number_phrase',\n",
       " 'lexapro',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'protonix',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'qd',\n",
       " 'number_phrase',\n",
       " 'aspirin',\n",
       " 'number_phrase',\n",
       " 'mg',\n",
       " 'qd',\n",
       " 'allergies',\n",
       " 'norvasc',\n",
       " 'leads',\n",
       " 'to',\n",
       " 'lightheadedness',\n",
       " 'and',\n",
       " 'headache',\n",
       " 'family',\n",
       " 'history',\n",
       " 'noncontributory',\n",
       " 'social',\n",
       " 'history',\n",
       " 'lives',\n",
       " 'with',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'dr',\n",
       " 'redacted_phrase',\n",
       " 'an',\n",
       " 'eminent',\n",
       " 'pediatric',\n",
       " 'neurologist',\n",
       " 'at',\n",
       " 'redacted_phrase',\n",
       " 'the',\n",
       " 'patient',\n",
       " 'is',\n",
       " 'a',\n",
       " 'prior',\n",
       " 'smoker',\n",
       " 'but',\n",
       " 'has',\n",
       " 'not',\n",
       " 'smoked',\n",
       " 'in',\n",
       " 'over',\n",
       " 'number_phrase',\n",
       " 'years',\n",
       " 'she',\n",
       " 'has',\n",
       " 'no',\n",
       " 'known',\n",
       " 'alcohol',\n",
       " 'use',\n",
       " 'and',\n",
       " 'she',\n",
       " 'is',\n",
       " 'a',\n",
       " 'full',\n",
       " 'code',\n",
       " 'physical',\n",
       " 'exam',\n",
       " 'at',\n",
       " 'time',\n",
       " 'of',\n",
       " 'admission',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'number_phrase',\n",
       " '/',\n",
       " 'number_phrase',\n",
       " 'heart',\n",
       " 'rate',\n",
       " 'number_phrase',\n",
       " 'and',\n",
       " 'regular',\n",
       " 'respirations',\n",
       " 'at',\n",
       " 'number_phrase',\n",
       " '-',\n",
       " 'number_phrase',\n",
       " 'and',\n",
       " 'number_phrase',\n",
       " 'axillary',\n",
       " 'temperature',\n",
       " 'she',\n",
       " 'was',\n",
       " 'saturating',\n",
       " 'at',\n",
       " 'number_phrase',\n",
       " 'on',\n",
       " 'cpap',\n",
       " 'with',\n",
       " 'dry',\n",
       " 'mucous',\n",
       " 'membranes',\n",
       " 'an',\n",
       " 'elderly',\n",
       " 'female',\n",
       " 'in',\n",
       " 'no',\n",
       " 'apparent',\n",
       " 'distress',\n",
       " 'pupils',\n",
       " 'are',\n",
       " 'equal',\n",
       " 'round',\n",
       " 'and',\n",
       " 'reactive',\n",
       " 'to',\n",
       " 'light',\n",
       " 'and',\n",
       " 'accommodation',\n",
       " 'extraocular',\n",
       " 'movements',\n",
       " 'are',\n",
       " 'intact',\n",
       " 'oropharynx',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'assess',\n",
       " 'due',\n",
       " 'to',\n",
       " 'cpap',\n",
       " 'machine',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'jugular',\n",
       " 'venous',\n",
       " 'pressure',\n",
       " 'however',\n",
       " 'the',\n",
       " 'strap',\n",
       " 'from',\n",
       " 'the',\n",
       " 'cpap',\n",
       " 'machine',\n",
       " 'obscures',\n",
       " 'the',\n",
       " 'neck',\n",
       " 'exam',\n",
       " 'cranial',\n",
       " 'nerves',\n",
       " 'ii',\n",
       " 'through',\n",
       " 'xii',\n",
       " 'are',\n",
       " 'grossly',\n",
       " 'intact',\n",
       " 'neck',\n",
       " 'is',\n",
       " 'supple',\n",
       " 'without',\n",
       " 'lymphadenopathy',\n",
       " 'heart',\n",
       " 'exam',\n",
       " 'tachycardic',\n",
       " 'regular',\n",
       " 'obscured',\n",
       " 'by',\n",
       " 'loud',\n",
       " 'bilateral',\n",
       " 'wheezing',\n",
       " 'with',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'the',\n",
       " 'expiratory',\n",
       " 'phase',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'profuse',\n",
       " 'scattered',\n",
       " 'rhonchi',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'lung',\n",
       " 'fields',\n",
       " 'positive',\n",
       " 'bowel',\n",
       " 'sounds',\n",
       " 'soft',\n",
       " 'nontender',\n",
       " 'nondistended',\n",
       " 'obese',\n",
       " 'no',\n",
       " 'masses',\n",
       " 'mild',\n",
       " 'edema',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lower',\n",
       " 'extremities',\n",
       " 'without',\n",
       " 'clubbing',\n",
       " 'or',\n",
       " 'cyanosis',\n",
       " 'no',\n",
       " 'rashes',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'right',\n",
       " 'hand',\n",
       " 'hematoma',\n",
       " 'strength',\n",
       " 'is',\n",
       " 'assessed',\n",
       " 'as',\n",
       " 'redacted_phrase',\n",
       " 'in',\n",
       " 'the',\n",
       " 'lower',\n",
       " 'extremities',\n",
       " 'redacted_phrase',\n",
       " 'in',\n",
       " 'the',\n",
       " 'upper',\n",
       " 'extremities',\n",
       " 'with',\n",
       " 'a',\n",
       " 'normal',\n",
       " 'mental',\n",
       " 'status',\n",
       " 'and',\n",
       " 'cognition',\n",
       " 'laboratory',\n",
       " 'studies',\n",
       " 'white',\n",
       " 'count',\n",
       " 'number_phrase',\n",
       " 'hematocrit',\n",
       " 'number_phrase',\n",
       " 'platelets',\n",
       " 'number_phrase',\n",
       " 'chem-',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'number_phrase',\n",
       " 'troponin',\n",
       " 'was',\n",
       " 'negative',\n",
       " 'cks',\n",
       " 'were',\n",
       " 'negative',\n",
       " 'times',\n",
       " 'three',\n",
       " 'initial',\n",
       " 'blood',\n",
       " 'gas',\n",
       " 'showed',\n",
       " 'a',\n",
       " 'ph',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'po2',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'pco2',\n",
       " 'of',\n",
       " 'number_phrase',\n",
       " 'chest',\n",
       " 'x-ray',\n",
       " 'demonstrates',\n",
       " 'a',\n",
       " 'moderate',\n",
       " 'sized',\n",
       " 'hiatal',\n",
       " 'hernia',\n",
       " 'segmental',\n",
       " 'atelectasis',\n",
       " 'left',\n",
       " 'lower',\n",
       " 'lobe',\n",
       " 'infiltrate',\n",
       " 'versus',\n",
       " 'segmental',\n",
       " 'atelectasis',\n",
       " 'ekg',\n",
       " 'shows',\n",
       " 'normal',\n",
       " 'sinus',\n",
       " 'rhythm',\n",
       " 'at',\n",
       " 'number_phrase',\n",
       " 'beats',\n",
       " 'per',\n",
       " 'minute',\n",
       " 'normal',\n",
       " 'axis',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'st-t',\n",
       " 'wave',\n",
       " 'changes',\n",
       " 'brief',\n",
       " 'summary',\n",
       " 'of',\n",
       " 'hospital',\n",
       " 'course',\n",
       " 'number_phrase',\n",
       " 'copd/dyspnea/pneumonia',\n",
       " 'the',\n",
       " 'patient',\n",
       " 'was',\n",
       " 'initially',\n",
       " 'placed',\n",
       " 'on',\n",
       " 'an',\n",
       " 'aggressive',\n",
       " 'steroid',\n",
       " 'taper',\n",
       " 'and',\n",
       " 'admitted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'medical',\n",
       " 'intensive',\n",
       " 'care',\n",
       " 'unit',\n",
       " 'due',\n",
       " 'to',\n",
       " 'her',\n",
       " 'difficulty',\n",
       " 'with',\n",
       " 'oxygenation',\n",
       " 'despite',\n",
       " 'cpap',\n",
       " 'machine',\n",
       " 'she',\n",
       " 'was',\n",
       " 'also',\n",
       " 'given',\n",
       " 'nebulizer',\n",
       " 'treatments',\n",
       " 'q4h',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'chest',\n",
       " 'pt',\n",
       " 'the',\n",
       " 'nebulizers',\n",
       " 'were',\n",
       " 'increased',\n",
       " 'to',\n",
       " 'q1h',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('number_phrase', 65),\n",
       " ('of', 39),\n",
       " ('the', 32),\n",
       " ('redacted_phrase', 22),\n",
       " ('to', 20),\n",
       " ('and', 19),\n",
       " ('a', 18),\n",
       " ('with', 18),\n",
       " ('in', 16),\n",
       " ('is', 13),\n",
       " ('on', 11),\n",
       " ('mg', 10),\n",
       " ('she', 9),\n",
       " ('was', 9),\n",
       " ('no', 9),\n",
       " ('as', 8),\n",
       " ('an', 7),\n",
       " ('qd', 7),\n",
       " ('at', 7),\n",
       " ('history', 6),\n",
       " ('are', 6),\n",
       " ('admission', 6),\n",
       " ('or', 6),\n",
       " ('date', 5),\n",
       " ('not', 5),\n",
       " ('predicted', 5),\n",
       " ('nebulizer', 5),\n",
       " ('ct', 5),\n",
       " ('has', 5),\n",
       " ('cpap', 5),\n",
       " ('by', 5),\n",
       " ('her', 5),\n",
       " ('this', 4),\n",
       " ('prior', 4),\n",
       " ('oxygen', 4),\n",
       " ('also', 4),\n",
       " ('chest', 4),\n",
       " ('normal', 4),\n",
       " ('been', 4),\n",
       " ('left', 4),\n",
       " ('treatment', 4),\n",
       " ('right', 4),\n",
       " ('patient', 4),\n",
       " ('pressure', 4),\n",
       " ('head', 4),\n",
       " ('evidence', 4),\n",
       " ('mild', 3),\n",
       " ('extremities', 3),\n",
       " ('consistent', 3),\n",
       " ('past', 3),\n",
       " ('rate', 3),\n",
       " ('shortness', 3),\n",
       " ('taper', 3),\n",
       " ('studies', 3),\n",
       " ('negative', 3),\n",
       " ('heart', 3),\n",
       " ('machine', 3),\n",
       " ('due', 3),\n",
       " ('showed', 3),\n",
       " ('most', 3),\n",
       " ('angina', 3),\n",
       " ('exam', 3),\n",
       " ('breath', 3),\n",
       " ('lower', 3),\n",
       " ('changes', 3),\n",
       " ('well', 3),\n",
       " ('without', 3),\n",
       " ('home', 3),\n",
       " ('for', 3),\n",
       " ('moderate', 3),\n",
       " ('be', 3),\n",
       " ('there', 3),\n",
       " ('but', 3),\n",
       " ('medical', 3),\n",
       " ('radiologic', 2),\n",
       " ('demonstrated', 2),\n",
       " ('likely', 2),\n",
       " ('never', 2),\n",
       " ('ekg', 2),\n",
       " ('positive', 2),\n",
       " ('known', 2),\n",
       " ('room', 2),\n",
       " ('following', 2),\n",
       " ('lexapro', 2),\n",
       " ('lesions', 2),\n",
       " ('synthroid', 2),\n",
       " ('blood', 2),\n",
       " ('bronchodilator', 2),\n",
       " ('neck', 2),\n",
       " ('years', 2),\n",
       " ('segmental', 2),\n",
       " ('atelectasis', 2),\n",
       " ('imaging', 2),\n",
       " ('care', 2),\n",
       " ('days', 2),\n",
       " ('service', 2),\n",
       " ('white', 2),\n",
       " ('copd', 2),\n",
       " ('that', 2),\n",
       " ('were', 2),\n",
       " ('abnormalities', 2),\n",
       " ('levofloxacin', 2),\n",
       " ('prednisone', 2),\n",
       " ('regular', 2),\n",
       " ('despite', 2),\n",
       " ('sinus', 2),\n",
       " ('secondary', 2),\n",
       " ('midline', 2),\n",
       " ('however', 2),\n",
       " ('steroid', 2),\n",
       " ('improve', 2),\n",
       " ('three', 2),\n",
       " ('rashes', 2),\n",
       " ('these', 2),\n",
       " ('nebulizers', 2),\n",
       " ('infarction', 2),\n",
       " ('recent', 2),\n",
       " ('maxillary', 2),\n",
       " ('fvc', 2),\n",
       " ('saturation', 2),\n",
       " ('emergency', 2),\n",
       " ('some', 2),\n",
       " ('intact', 2),\n",
       " ('demonstrates', 2),\n",
       " ('does', 2),\n",
       " ('abdominal', 2),\n",
       " ('lung', 2),\n",
       " ('female', 2),\n",
       " ('flow', 2),\n",
       " ('discharge', 2),\n",
       " ('bilateral', 2),\n",
       " ('mass', 2),\n",
       " ('represent', 1),\n",
       " ('code', 1),\n",
       " ('saturating', 1),\n",
       " ('medquist36', 1),\n",
       " ('four', 1),\n",
       " ('obstruction', 1),\n",
       " ('nitroglycerin', 1),\n",
       " ('per', 1),\n",
       " ('hernia', 1),\n",
       " ('oxygenation', 1),\n",
       " ('osteoporosis', 1),\n",
       " ('increase', 1),\n",
       " ('presents', 1),\n",
       " ('preserved', 1),\n",
       " ('rhythm', 1),\n",
       " ('wave', 1),\n",
       " ('minute', 1),\n",
       " ('nausea', 1),\n",
       " ('leads', 1),\n",
       " ('presented', 1),\n",
       " ('t2', 1),\n",
       " ('mucosal', 1),\n",
       " ('phase', 1),\n",
       " ('small', 1),\n",
       " ('hypothyroidism', 1),\n",
       " ('shows', 1),\n",
       " ('noted', 1),\n",
       " ('upper', 1),\n",
       " ('turcica', 1),\n",
       " ('q1h', 1),\n",
       " ('orthopnea', 1),\n",
       " ('depression', 1),\n",
       " ('sweats', 1),\n",
       " ('eminent', 1),\n",
       " ('full', 1),\n",
       " ('ventilatory', 1),\n",
       " ('degree', 1),\n",
       " ('vomiting', 1),\n",
       " ('change', 1),\n",
       " ('dry', 1),\n",
       " ('cranial', 1),\n",
       " ('shift', 1),\n",
       " ('study', 1),\n",
       " ('etiology', 1),\n",
       " ('pediatric', 1),\n",
       " ('social', 1),\n",
       " ('neurologist', 1),\n",
       " ('followed', 1),\n",
       " ('family', 1),\n",
       " ('strap', 1),\n",
       " ('motor', 1),\n",
       " ('unit', 1),\n",
       " ('albuterol', 1),\n",
       " ('use', 1),\n",
       " ('from', 1),\n",
       " ('hospital', 1),\n",
       " ('few', 1),\n",
       " ('nontender', 1),\n",
       " ('vehicle', 1),\n",
       " ('tachycardic', 1),\n",
       " ('injury', 1),\n",
       " ('type', 1),\n",
       " ('ischemia', 1),\n",
       " ('ischemic', 1),\n",
       " ('started', 1),\n",
       " ('apparent', 1),\n",
       " ('outpatient', 1),\n",
       " ('reversible', 1),\n",
       " ('md', 1),\n",
       " ('f', 1),\n",
       " ('foci', 1),\n",
       " ('can', 1),\n",
       " ('process', 1),\n",
       " ('pons', 1),\n",
       " ('high', 1),\n",
       " ('palpitations', 1),\n",
       " ('times', 1),\n",
       " ('axis', 1),\n",
       " ('expiratory', 1),\n",
       " ('hematoma', 1),\n",
       " ('occasionally', 1),\n",
       " ('venous', 1),\n",
       " ('movements', 1),\n",
       " ('product', 1),\n",
       " ('lesion', 1),\n",
       " ('stress', 1),\n",
       " ('light', 1),\n",
       " ('maintain', 1),\n",
       " ('process/tuberculosis', 1),\n",
       " ('order', 1),\n",
       " ('over', 1),\n",
       " ('course', 1),\n",
       " ('through', 1),\n",
       " ('gastrointestinal', 1),\n",
       " ('imdur', 1),\n",
       " ('apex', 1),\n",
       " ('masses', 1),\n",
       " ('clubbing', 1),\n",
       " ('symptoms', 1),\n",
       " ('oropharynx', 1),\n",
       " ('systems', 1),\n",
       " ('versus', 1),\n",
       " ('then', 1),\n",
       " ('greater', 1),\n",
       " ('lightheadedness', 1),\n",
       " ('frontal', 1),\n",
       " ('day', 1),\n",
       " ('troponin', 1),\n",
       " ('cognition', 1),\n",
       " ('status', 1),\n",
       " ('significantly', 1),\n",
       " ('weight', 1),\n",
       " ('jugular', 1),\n",
       " ('related', 1),\n",
       " ('blocks', 1),\n",
       " ('medications', 1),\n",
       " ('alcohol', 1),\n",
       " ('fevers', 1),\n",
       " ('cerebral', 1),\n",
       " ('emphysema', 1),\n",
       " ('tests', 1),\n",
       " ('medicine', 1),\n",
       " ('treatments', 1),\n",
       " ('difficulty', 1),\n",
       " ('mmf', 1),\n",
       " ('accommodation', 1),\n",
       " ('protonix', 1),\n",
       " ('flare', 1),\n",
       " ('could', 1),\n",
       " ('round', 1),\n",
       " ('chills', 1),\n",
       " ('loud', 1),\n",
       " ('major', 1),\n",
       " ('initial', 1),\n",
       " ('primary', 1),\n",
       " ('one', 1),\n",
       " ('enlarged', 1),\n",
       " ('sounds', 1),\n",
       " ('hiatal', 1),\n",
       " ('given', 1),\n",
       " ('temperature', 1),\n",
       " ('xii', 1),\n",
       " ('moderately', 1),\n",
       " ('approximately', 1),\n",
       " ('ethmoid', 1),\n",
       " ('headache', 1),\n",
       " ('bowel', 1),\n",
       " ('x2', 1),\n",
       " ('than', 1),\n",
       " ('infiltrate', 1),\n",
       " ('copd/dyspnea/pneumonia', 1),\n",
       " ('infectious', 1),\n",
       " ('matter', 1),\n",
       " ('profuse', 1),\n",
       " ('illness', 1),\n",
       " ('membranes', 1),\n",
       " ('sella', 1),\n",
       " ('prn', 1),\n",
       " ('defect', 1),\n",
       " ('strength', 1),\n",
       " ('pupils', 1),\n",
       " ('pleural', 1),\n",
       " ('allergies', 1),\n",
       " ('latter', 1),\n",
       " ('able', 1),\n",
       " ('predominantly', 1),\n",
       " ('positionally', 1),\n",
       " ('which', 1),\n",
       " ('multiple', 1),\n",
       " ('who', 1),\n",
       " ('complaints', 1),\n",
       " ('assessed', 1),\n",
       " ('episode', 1),\n",
       " ('calculated', 1),\n",
       " ('hydrocephalus', 1),\n",
       " ('mri', 1),\n",
       " ('nonspecific', 1),\n",
       " ('fact', 1),\n",
       " ('walking', 1),\n",
       " ('scattered', 1),\n",
       " ('sublingual', 1),\n",
       " ('brief', 1),\n",
       " ('aggressive', 1),\n",
       " ('ratio', 1),\n",
       " ('q4', 1),\n",
       " ('reactive', 1),\n",
       " ('going', 1),\n",
       " ('subtotally', 1),\n",
       " ('lobe', 1),\n",
       " ('dr', 1),\n",
       " ('q4h', 1),\n",
       " ('intensive', 1),\n",
       " ('fields', 1),\n",
       " ('summary', 1),\n",
       " ('hemispheres', 1),\n",
       " ('husband', 1),\n",
       " ('sex', 1),\n",
       " ('review', 1),\n",
       " ('vascular', 1),\n",
       " ('initially', 1),\n",
       " ('job', 1),\n",
       " ('hand', 1),\n",
       " ('both', 1),\n",
       " ('accident', 1),\n",
       " ('last', 1),\n",
       " ('region', 1),\n",
       " ('equal', 1),\n",
       " ('cavitary', 1),\n",
       " ('inflammatory', 1),\n",
       " ('distress', 1),\n",
       " ('noncontributory', 1),\n",
       " ('lacunar', 1),\n",
       " ('pulmonary', 1),\n",
       " ('supple', 1),\n",
       " ('better', 1),\n",
       " ('pulmicort', 1),\n",
       " ('pt', 1),\n",
       " ('addition', 1),\n",
       " ('wheezing', 1),\n",
       " ('ph', 1),\n",
       " ('norvasc', 1),\n",
       " ('empty', 1),\n",
       " ('respirations', 1),\n",
       " ('obese', 1),\n",
       " ('mcg', 1),\n",
       " ('gas', 1),\n",
       " ('strictures', 1),\n",
       " ('intubated', 1),\n",
       " ('lives', 1),\n",
       " ('present', 1),\n",
       " ('moderate-sized', 1),\n",
       " ('ejection', 1),\n",
       " ('beats', 1),\n",
       " ('air', 1),\n",
       " ('while', 1),\n",
       " ('cva', 1),\n",
       " ('solu-medrol', 1),\n",
       " ('iv', 1),\n",
       " ('ii', 1),\n",
       " ('confirmed', 1),\n",
       " ('-year-old', 1),\n",
       " ('doctor', 1),\n",
       " ('gets', 1),\n",
       " ('bid', 1),\n",
       " ('difficult', 1),\n",
       " ('exertion', 1),\n",
       " ('myocardial', 1),\n",
       " ('effect', 1),\n",
       " ('sacrum', 1),\n",
       " ('pco2', 1),\n",
       " ('off', 1),\n",
       " ('smoker', 1),\n",
       " ('thought', 1),\n",
       " ('patterns', 1),\n",
       " ('smoked', 1),\n",
       " ('grossly', 1),\n",
       " ('edema', 1),\n",
       " ('-', 1),\n",
       " ('rest', 1),\n",
       " ('underlying', 1),\n",
       " ('rhonchi', 1),\n",
       " ('thickening', 1),\n",
       " ('increased', 1),\n",
       " ('birth', 1),\n",
       " ('axillary', 1),\n",
       " ('d', 1),\n",
       " ('signal', 1),\n",
       " ('fev1', 1),\n",
       " ('admitted', 1),\n",
       " ('sized', 1),\n",
       " ('t', 1),\n",
       " ('night', 1),\n",
       " ('nerves', 1),\n",
       " ('soft', 1),\n",
       " ('effusion', 1),\n",
       " ('old', 1),\n",
       " ('elderly', 1),\n",
       " ('restrictive', 1),\n",
       " ('hemorrhage', 1),\n",
       " ('fev1fvc', 1),\n",
       " ('throughout', 1),\n",
       " ('/', 1),\n",
       " ('t10', 1),\n",
       " ('nondistended', 1),\n",
       " ('o2', 1),\n",
       " ('minimal', 1),\n",
       " ('neurologic', 1),\n",
       " ('obscures', 1),\n",
       " ('hematocrit', 1),\n",
       " ('obscured', 1),\n",
       " ('dictated', 1),\n",
       " ('getting', 1),\n",
       " ('cyanosis', 1),\n",
       " ('addendum', 1),\n",
       " ('within', 1),\n",
       " ('two', 1),\n",
       " ('assess', 1),\n",
       " ('chronic', 1),\n",
       " ('mental', 1),\n",
       " ('extraocular', 1),\n",
       " ('fraction', 1),\n",
       " ('allergic', 1),\n",
       " ('function', 1),\n",
       " ('platelets', 1),\n",
       " ('micu', 1),\n",
       " ('intracranial', 1),\n",
       " ('count', 1),\n",
       " ('improved', 1),\n",
       " ('microvascular', 1),\n",
       " ('maximum', 1),\n",
       " ('placed', 1),\n",
       " ('hydrochlorothiazide', 1),\n",
       " ('aspirin', 1),\n",
       " ('minutes', 1),\n",
       " ('x-ray', 1),\n",
       " ('st-t', 1),\n",
       " ('laboratory', 1),\n",
       " ('mucous', 1),\n",
       " ('physical', 1),\n",
       " ('weaned', 1),\n",
       " ('other', 1),\n",
       " ('chem-', 1),\n",
       " ('test', 1),\n",
       " ('denies', 1),\n",
       " ('repeat', 1),\n",
       " ('cks', 1),\n",
       " ('po2', 1),\n",
       " ('lymphadenopathy', 1),\n",
       " ('sphenoid', 1),\n",
       " ('alleviated', 1),\n",
       " ('additionally', 1),\n",
       " ('included', 1),\n",
       " ('ago', 1),\n",
       " ('required', 1),\n",
       " ('portion', 1),\n",
       " ('time', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(all_words[:1000]).most_common(vocabulary_size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_index = 0\n",
    "# line_index = 0\n",
    "# # generate batch data\n",
    "# def generate_batch(data, batch_size, num_skips, skip_window):\n",
    "#     global data_index\n",
    "#     assert batch_size % num_skips == 0\n",
    "#     assert num_skips <= 2 * skip_window\n",
    "#     batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "#     context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "#     span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "#     buffer = collections.deque(maxlen=span)\n",
    "#     while len(buffer) < span:\n",
    "#         buffer = collections.deque(maxlen=span)\n",
    "#         for _ in range(span):\n",
    "#             buffer.append(data[line_index][data_index])\n",
    "#             data_index += 1\n",
    "#             if data_index > len(data[line_index]):\n",
    "#                 line_index += 1\n",
    "#                 break\n",
    "                \n",
    "#     for i in range(batch_size // num_skips):\n",
    "#         target = skip_window  # input word at the center of the buffer\n",
    "#         targets_to_avoid = [skip_window]\n",
    "#         for j in range(num_skips):\n",
    "#             while target in targets_to_avoid:\n",
    "#                 target = random.randint(0, span - 1)\n",
    "#             targets_to_avoid.append(target)\n",
    "#             batch[i * num_skips + j] = buffer[skip_window]  # this is the input word\n",
    "#             context[i * num_skips + j, 0] = buffer[target]  # these are the context words\n",
    "#         buffer.append(data[data_index])\n",
    "#         data_index = (data_index + 1) % len(data)\n",
    "#     # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "#     data_index = (data_index + len(data) - span) % len(data)\n",
    "#     return batch, context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_index = 0\n",
    "# generate batch data\n",
    "def generate_batch(data, batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # input word at the center of the buffer\n",
    "        targets_to_avoid = [skip_window]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]  # this is the input word\n",
    "            context[i * num_skips + j, 0] = buffer[target]  # these are the context words\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected data\n",
      "WARNING:tensorflow:From <ipython-input-26-bf3cd3b636b4>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-26-bf3cd3b636b4>:45: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "print (\"collected data\")\n",
    "batch_size = 128\n",
    "embedding_size = 300  # Dimension of the embedding vector.\n",
    "skip_window = 2       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_context = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "    # Construct the variables for the softmax\n",
    "    weights = tf.Variable(\n",
    "            tf.truncated_normal([embedding_size, vocabulary_size],\n",
    "                                                    stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    hidden_out = tf.transpose(tf.matmul(tf.transpose(weights), tf.transpose(embed))) + biases\n",
    "\n",
    "    # convert train_context to a one-hot format\n",
    "    train_one_hot = tf.one_hot(train_context, vocabulary_size)\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hidden_out, labels=train_one_hot))\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(cross_entropy)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(graph, num_steps):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        # We must initialize all variables before we use them.\n",
    "        init.run()\n",
    "        print('Initialized')\n",
    "\n",
    "        average_loss = 0\n",
    "        for step in range(num_steps):\n",
    "            batch_inputs, batch_context = generate_batch(data,\n",
    "                    batch_size, num_skips, skip_window)\n",
    "            feed_dict = {train_inputs: batch_inputs, train_context: batch_context}\n",
    "\n",
    "            # We perform one update step by evaluating the optimizer op (including it\n",
    "            # in the list of returned values for session.run()\n",
    "            _, loss_val = session.run([optimizer, cross_entropy], feed_dict=feed_dict)\n",
    "            average_loss += loss_val\n",
    "\n",
    "            if step % 2000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 2000\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "                print('Average loss at step ', step, ': ', average_loss)\n",
    "                average_loss = 0\n",
    "\n",
    "            # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                    top_k = 8  # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log_str = 'Nearest to %s:' % valid_word\n",
    "#                     print (len(nearest), sim.shape, nearest, sim)\n",
    "                    for k in range(top_k):\n",
    "                        close_word = reverse_dictionary[nearest[k]]\n",
    "                        log_str = '%s %s,' % (log_str, close_word)\n",
    "                    print(log_str)\n",
    "        final_embeddings = normalized_embeddings.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "('Average loss at step ', 0, ': ', 9.390083312988281)\n",
      "Nearest to his: wounds, coursing, vocal, managing, fam, neuropathy, assist, rigidity,\n",
      "Nearest to fluid: ph-, insulin, mono40, esophagectomy, agreement, pivs, confluent, vanc/cefepime,\n",
      "Nearest to prior: colored, titrate, biphasic, osteolytic, hematology, feed, appeared, within,\n",
      "Nearest to bp: planes, tarry, fixation, cc/kg/d, bs+, scalp, hematemesis, partner,\n",
      "Nearest to patient: neuropt, ------, mouth, be, drifts, period, prevertebral, outline,\n",
      "Nearest to /: appt, cabg, balloon, submandibular, replaced, dtrs, lfts, 9am,\n",
      "Nearest to tube: shocked, widowed, memory, post-pyloric, q2hprn, dentition, climb, urine,\n",
      "Nearest to ml: intraperitoneal, cta, adequate, sure, -cm, revealed, ob-, eval,\n",
      "Nearest to he: malformation, ruq, bending, eosinophils, multilobar, elderly, sicu-a, administered,\n",
      "Nearest to ct: directed, expectorated, seemed, *you, sequence, in-house, 75mg, orally,\n",
      "Nearest to at: operation, digoxin, pa02, alb/atr, levo, oxycodone-acetaminophen, cyanocobalamin, slight,\n",
      "Nearest to iv: otherwise, optimize, curved, gaseous, failure, overweight, alternatively, neuropt,\n",
      "Nearest to daily: scanning, pboots, paraesophageal, 18g, fonts, erect, ffp, evaluated,\n",
      "Nearest to on: sc, distention, extensor, inr136/, gnr, azithromycin, gb, commode,\n",
      "Nearest to this: ronchi, weighted, synthroid, inhibitors, providers, zoloft, flush, support,\n",
      "Nearest to is: 2u, wdwn, 130cc/k/d, friable, node, 12am, displays, induration,\n",
      "('Average loss at step ', 2000, ': ', 6.6226811897754665)\n",
      "('Average loss at step ', 4000, ': ', 6.084767979383469)\n",
      "('Average loss at step ', 6000, ': ', 5.94782702255249)\n",
      "('Average loss at step ', 8000, ': ', 5.831106980323791)\n",
      "('Average loss at step ', 10000, ': ', 5.820660742282867)\n",
      "Nearest to his: the, coursing, managing, bridge, attributed, accordingly, gi, nkda,\n",
      "Nearest to fluid: mono40, insulin, ph-, agreement, esophagectomy, confluent, pivs, knee,\n",
      "Nearest to prior: colored, titrate, biphasic, osteolytic, hematology, feed, vasc, info,\n",
      "Nearest to bp: tarry, cc/kg/d, fixation, planes, bs+, hematemesis, red, partner,\n",
      "Nearest to patient: period, neuropt, be, he, drifts, she, ------, prevertebral,\n",
      "Nearest to /: submandibular, appt, cabg, replaced, 9am, lfts, dtrs, balloon,\n",
      "Nearest to tube: widowed, shocked, memory, same, dentition, resuscitation, post-pyloric, urine,\n",
      "Nearest to ml: cta, adequate, staining, -cm, revealed, ob-, hypocaloric, intraperitoneal,\n",
      "Nearest to he: malformation, she, bending, ruq, patient, eosinophils, administered, elderly,\n",
      "Nearest to ct: expectorated, seemed, directed, sequence, rests, *you, in-house, 75mg,\n",
      "Nearest to at: operation, digoxin, pa02, slight, levo, granulomas, alb/atr, diaphragmatic,\n",
      "Nearest to iv: optimize, otherwise, gaseous, neuropt, failure, overweight, curved, s/p,\n",
      "Nearest to daily: scanning, mg, pboots, erect, fonts, 18g, number_phrase, ec,\n",
      "Nearest to on: home, azithromycin, commode, inr136/, 1230pm, sc, distention, extensor,\n",
      "Nearest to this: ronchi, inhibitors, support, flush, alkalotic, previous, weighted, synthroid,\n",
      "Nearest to is: was, waking, 12am, 2u, hundred, displays, wdwn, ascities,\n",
      "('Average loss at step ', 12000, ': ', 5.724046718120575)\n",
      "('Average loss at step ', 14000, ': ', 5.799510485291481)\n",
      "('Average loss at step ', 16000, ': ', 5.6401594177484515)\n",
      "('Average loss at step ', 18000, ': ', 5.617920973181724)\n",
      "Softmax method took 3561.108579 seconds to run 20000 iterations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_steps = 20000\n",
    "softmax_start_time = dt.datetime.now()\n",
    "run(graph, num_steps=num_steps)\n",
    "softmax_end_time = dt.datetime.now()\n",
    "print(\"Softmax method took {} seconds to run 20000 iterations\".format((softmax_end_time-softmax_start_time).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Construct the variables for the NCE loss\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    nce_loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(weights=nce_weights,\n",
    "                       biases=nce_biases,\n",
    "                       labels=train_context,\n",
    "                       inputs=embed,\n",
    "                       num_sampled=num_sampled,\n",
    "                       num_classes=vocabulary_size))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(nce_loss)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "('Average loss at step ', 0, ': ', 9.33537483215332)\n",
      "Nearest to his: wedge-shaped, bm26, cvas, rhonchorus, untreated, acuity, seal, interdisciplinary,\n",
      "Nearest to fluid: evaluate, cholecystitis, discussing, frx, vite, mcg/hr, lordosis, reported,\n",
      "Nearest to prior: l-spine, modest, species, quads, sao2, prong, narcotic, bile,\n",
      "Nearest to bp: 650mg, betamethasone, fashion, nif, obscures, tobra, dfdkq, bm30,\n",
      "Nearest to patient: static, anesthesia, guidelines, appreciable, tolerating, intrathoracic, indicative, checklist,\n",
      "Nearest to /: cuffed, antibiotics, organisms/ml, boy, lines, food, w&w/oc, true,\n",
      "Nearest to tube: neurogenic, cardiorespiratory, levofloxacin, esophagectomy, monitored, mvi, intramural, cleaned,\n",
      "Nearest to ml: callus, moderate-to-large, markedly, not/guidepnonlaser, program, cordis/introducer, dementia, very,\n",
      "Nearest to he: encouragement, significant, cefpodoxime, unrestrained, hundred, police, watching, bm/sc,\n",
      "Nearest to ct: va, reversal, poor, postop, correctly, g/dl, transitioned, despite,\n",
      "Nearest to at: eyes, small, not, ureters, map, enzymes, actual, grip,\n",
      "Nearest to iv: consistencies, tachy, ugi, 0540am, does, dipyridamole, displaced, lobectomy,\n",
      "Nearest to daily: result, parieto-occipital, f/up, modified, fe, adjusting, daycare, dusky,\n",
      "Nearest to on: fx, mild, fallen, q4hr, intracranial, restricted, vecuronium, phenylephrine,\n",
      "Nearest to this: dramatic, stenting, acid19, e/e, become, resp/cv, inside, penicillin,\n",
      "Nearest to is: machine, va, lysis, obtunded, rise, dfddp, head, destructive,\n",
      "('Average loss at step ', 2000, ': ', 9.330236711978912)\n",
      "('Average loss at step ', 4000, ': ', 9.317054291725158)\n",
      "('Average loss at step ', 6000, ': ', 9.309615000724792)\n",
      "('Average loss at step ', 8000, ': ', 9.30696557378769)\n",
      "('Average loss at step ', 10000, ': ', 9.304353563308716)\n",
      "Nearest to his: her, drop, your, number_phrase, nsr, scrotal, 1230pm, flu,\n",
      "Nearest to fluid: evaluate, reported, superior, compared, cholecystitis, mcg/hr, discussing, purpose,\n",
      "Nearest to prior: was, l-spine, modest, narcotic, species, wnl, frequent, sao2,\n",
      "Nearest to bp: 650mg, number_phrase, fashion, meals, ep, nif, neutropenia, trouble,\n",
      "Nearest to patient: he, to, and, she, anesthesia, UNK, rv, ileus,\n",
      "Nearest to /: lines, organisms/ml, markedly, antibiotics, food, fat, packed, english,\n",
      "Nearest to tube: levofloxacin, monitored, disp*, mvi, cardiorespiratory, co2-, chb, intramural,\n",
      "Nearest to ml: number_phrase, and, UNK, markedly, dementia, moderate-to-large, program, bowel,\n",
      "Nearest to he: patient, significant, the, cefpodoxime, she, encouragement, bili-, hundred,\n",
      "Nearest to ct: transitioned, poor, postop, reversal, with, despite, five, cholesterol,\n",
      "Nearest to at: eyes, small, not, enzymes, map, question, separate, number_phrase,\n",
      "Nearest to iv: UNK, 0540am, does, bedtime, consistencies, lobectomy, verapamil, tachy,\n",
      "Nearest to daily: number_phrase, result, exact, screws, and, *, fe, wnl,\n",
      "Nearest to on: number_phrase, and, UNK, to, mild, fx, recorded, po/ng,\n",
      "Nearest to this: stenting, arterial, the, examination, her, cystoscopy, st, 0900pm,\n",
      "Nearest to is: was, UNK, and, machine, ns, of, indications, obtunded,\n",
      "('Average loss at step ', 12000, ': ', 9.303360674381256)\n",
      "('Average loss at step ', 14000, ': ', 9.301341750144958)\n",
      "('Average loss at step ', 16000, ': ', 9.299748915195465)\n",
      "('Average loss at step ', 18000, ': ', 9.298383339881896)\n",
      "NCE method took 2226.358731 seconds to run 20000 iterations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_steps = 20000\n",
    "nce_start_time = dt.datetime.now()\n",
    "run(graph, num_steps)\n",
    "nce_end_time = dt.datetime.now()\n",
    "print(\"NCE method took {} seconds to run 20000 iterations\".format((nce_end_time-nce_start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "('Average loss at step ', 0, ': ', 9.251243591308594)\n",
      "Nearest to his: font, gall, aquacel, gluconate, needed, hand, ligation, vitamins,\n",
      "Nearest to fluid: destination, nimodipine, sidelying, dht, irregularly, inch, imp-infant, ep,\n",
      "Nearest to prior: ordering, eff, fick, suffered, precipitated, sulcus, /abd/para, s-,\n",
      "Nearest to bp: multiple, atrium, alcohol, neoplastic, reference, get, kayexalate, hypocaloric,\n",
      "Nearest to patient: 3cm, norepinephrine, stage, ammonia, suture, yielding, phenergan, sheaths,\n",
      "Nearest to /: waiting, phosphate-, mmol/l, felt, brachial, re-expansion, note, clinically,\n",
      "Nearest to tube: ultrasounds, bright, losses, aphasia, arthroplasty, rests, sbp160, poc,\n",
      "Nearest to ml: aerosol, hemorrhagic, gross, 10l, banana, 45min, gums, sample,\n",
      "Nearest to he: 10th, hypovolemia, 90s-100s, fields, abuse, dsgs, issues, cms,\n",
      "Nearest to ct: dislocations, sequence, 1000x, urean-, thrills, surgeon, nutritional, 2nd,\n",
      "Nearest to at: azotemia, luminal, na+-, s3, tf150cc/kg/day, complaint, cerebellum, grade,\n",
      "Nearest to iv: click, thrombocytopeni, phos-, combination, kerlix, 200s, vegetations, gait,\n",
      "Nearest to daily: gi/gu-, cbg, characteristics, paged, bronchiectasis, sense, something, page,\n",
      "Nearest to on: unclear, worked, palatal, underwent, leaflets, understood, nodding, aches,\n",
      "Nearest to this: thrive, attentive, nbp, d/c, downward, mcg/kg, tendon, signal,\n",
      "Nearest to is: pounds, rinse, dullness, ms04, mso4, gd, dermatology, atenolol,\n",
      "('Average loss at step ', 2000, ': ', 9.313357792377472)\n",
      "('Average loss at step ', 4000, ': ', 9.30352213716507)\n",
      "('Average loss at step ', 6000, ': ', 9.299073906421661)\n",
      "('Average loss at step ', 8000, ': ', 9.291141652584075)\n",
      "('Average loss at step ', 10000, ': ', 9.28801299905777)\n",
      "Nearest to his: the, her, hand, 0900pm, gluconate, c, fusion, number_phrase,\n",
      "Nearest to fluid: UNK, dht, ep, plan, klonopin, similar, saturation, arteriovenous,\n",
      "Nearest to prior: number_phrase, finding, into, suffered, kidneys, no, west, outpatient,\n",
      "Nearest to bp: multiple, UNK, atrium, get, reference, kayexalate, alcohol, u,\n",
      "Nearest to patient: hypo, and, she, he, you, stage, ulcers, suture,\n",
      "Nearest to /: phosphate-, abs, felt, waiting, re-expansion, chloride-, dnr/dni, bipap,\n",
      "Nearest to tube: ultrasounds, bright, taken, losses, arthroplasty, aphasia, advised, postoperatively,\n",
      "Nearest to ml: aerosol, hemorrhagic, number_phrase, gross, m/sec, opacification, stomach, quickly,\n",
      "Nearest to he: she, the, and, patient, syncopal, describes, chemo, clonidine,\n",
      "Nearest to ct: urean-, surgeon, 1000x, thrills, underwent, nutritional, dislocations, 2nd,\n",
      "Nearest to at: azotemia, UNK, luminal, na+-, on, hypo, x-rays, thrombolysis,\n",
      "Nearest to iv: click, combination, phos-, UNK, with, gait, number_phrase, pmh,\n",
      "Nearest to daily: number_phrase, redacted_phrase, hypo, *, UNK, triglyc-, pounds, once,\n",
      "Nearest to on: UNK, number_phrase, and, to, abs, culture-final, worked, for,\n",
      "Nearest to this: the, downward, thrive, d/c, attentive, signal, yo, compliant,\n",
      "Nearest to is: was, pounds, hypo, UNK, atenolol, cord, fever, to,\n",
      "('Average loss at step ', 12000, ': ', 9.285362570285796)\n",
      "('Average loss at step ', 14000, ': ', 9.286525103092194)\n",
      "('Average loss at step ', 16000, ': ', 9.282957625389098)\n",
      "('Average loss at step ', 18000, ': ', 9.279698077678681)\n",
      "('Average loss at step ', 20000, ': ', 9.281853935241699)\n",
      "Nearest to his: her, the, UNK, number_phrase, c, your, gluconate, 0900pm,\n",
      "Nearest to fluid: destination, UNK, dht, ep, thrombectomy, klonopin, arteriovenous, similar,\n",
      "Nearest to prior: number_phrase, move, finding, outpatient, spine, bronchoalveolar, on, into,\n",
      "Nearest to bp: multiple, atrium, reference, kayexalate, get, alcohol, u, s1s2,\n",
      "Nearest to patient: he, she, hypo, you, to, suture, ulcers, and,\n",
      "Nearest to /: abs, phosphate-, felt, re-expansion, chloride-, alk, waiting, chloride,\n",
      "Nearest to tube: taken, ultrasounds, bright, losses, arthroplasty, aphasia, compensation, advised,\n",
      "Nearest to ml: aerosol, hemorrhagic, tablet, gross, 10l, m/sec, quickly, opacification,\n",
      "Nearest to he: she, patient, and, the, you, UNK, iabp, hypo,\n",
      "Nearest to ct: urean-, he, surgeon, dislocations, 2nd, thrills, nutritional, sequence,\n",
      "Nearest to at: azotemia, on, luminal, number_phrase, na+-, hypo, x-rays, UNK,\n",
      "Nearest to iv: click, with, number_phrase, combination, phos-, po, then, pmh,\n",
      "Nearest to daily: number_phrase, *, hypo, day, once, UNK, qd, redacted_phrase,\n",
      "Nearest to on: number_phrase, UNK, and, meq/l, to, was, in, culture-final,\n",
      "Nearest to this: the, d/c, thrive, downward, attentive, it, agreed, questioned,\n",
      "Nearest to is: was, hypo, of, pounds, gap-, with, example, the,\n",
      "('Average loss at step ', 22000, ': ', 9.280871829986573)\n",
      "('Average loss at step ', 24000, ': ', 9.28091611289978)\n",
      "('Average loss at step ', 26000, ': ', 9.278650362968445)\n",
      "('Average loss at step ', 28000, ': ', 9.278792233943939)\n",
      "('Average loss at step ', 30000, ': ', 9.27644306564331)\n",
      "Nearest to his: her, the, your, number_phrase, and, with, c, gluconate,\n",
      "Nearest to fluid: destination, nimodipine, similar, dht, thrombectomy, ep, inch, arteriovenous,\n",
      "Nearest to prior: number_phrase, outpatient, move, bronchoalveolar, west, spine, finding, kidneys,\n",
      "Nearest to bp: multiple, get, reference, UNK, atrium, anti-inflammatory, kayexalate, u,\n",
      "Nearest to patient: she, he, hypo, you, on, number_phrase, to, pt,\n",
      "Nearest to /: *, abs, phosphate-, felt, mg, re-expansion, chloride-, alk,\n",
      "Nearest to tube: taken, ultrasounds, bright, losses, arthroplasty, compensation, aphasia, gravity,\n",
      "Nearest to ml: aerosol, hemorrhagic, tablet, number_phrase, gross, hct-, 10l, banana,\n",
      "Nearest to he: she, patient, and, you, number_phrase, the, UNK, on,\n",
      "Nearest to ct: urean-, dislocations, he, thrills, underwent, 2nd, surgeon, sequence,\n",
      "Nearest to at: azotemia, on, UNK, hypo, in, number_phrase, luminal, x-rays,\n",
      "Nearest to iv: click, number_phrase, then, combination, po, with, 200s, phos-,\n",
      "Nearest to daily: number_phrase, *, day, qd, mg, hypo, once, redacted_phrase,\n",
      "Nearest to on: number_phrase, and, UNK, meq/l, with, culture-final, hypo, to,\n",
      "Nearest to this: the, thrive, d/c, it, questioned, redacted_phrase, attentive, agreed,\n",
      "Nearest to is: was, of, hypo, with, has, limb, example, number_phrase,\n",
      "('Average loss at step ', 32000, ': ', 9.276169096469879)\n",
      "('Average loss at step ', 34000, ': ', 9.276967475891114)\n",
      "('Average loss at step ', 36000, ': ', 9.275841845035552)\n",
      "('Average loss at step ', 38000, ': ', 9.276715812206268)\n",
      "('Average loss at step ', 40000, ': ', 9.27571533727646)\n",
      "Nearest to his: her, the, your, and, patients, redacted_phrase, with, number_phrase,\n",
      "Nearest to fluid: destination, nimodipine, similar, dht, allow, thrombectomy, inch, ep,\n",
      "Nearest to prior: move, outpatient, west, number_phrase, bronchoalveolar, redacted_phrase, clubbing, spine,\n",
      "Nearest to bp: multiple, anti-inflammatory, get, reference, u, atrium, neoplastic, alcohol,\n",
      "Nearest to patient: she, he, pt, hypo, UNK, you, to, and,\n",
      "Nearest to /: abs, *, mg, phosphate-, number_phrase, felt, isosorbide, chloride,\n",
      "Nearest to tube: taken, ultrasounds, bright, losses, compensation, arthroplasty, gravity, placement,\n",
      "Nearest to ml: aerosol, number_phrase, tablet, hemorrhagic, gross, 10l, hct-, sodium-,\n",
      "Nearest to he: she, patient, and, you, hypo, pt, UNK, there,\n",
      "Nearest to ct: he, urean-, underwent, redacted_phrase, sequence, dislocations, thrills, 1000x,\n",
      "Nearest to at: on, azotemia, UNK, in, number_phrase, luminal, hypo, x-rays,\n",
      "Nearest to iv: po, click, phos-, 200s, then, mcv, atorvastatin, combination,\n",
      "Nearest to daily: mg, *, qd, number_phrase, day, hypo, once, redacted_phrase,\n",
      "Nearest to on: UNK, and, meq/l, in, number_phrase, at, redacted_phrase, to,\n",
      "Nearest to this: the, thrive, d/c, it, which, redacted_phrase, he, questioned,\n",
      "Nearest to is: was, of, with, UNK, has, and, -, hypo,\n",
      "('Average loss at step ', 42000, ': ', 9.275083745479584)\n",
      "('Average loss at step ', 44000, ': ', 9.274478417873382)\n",
      "('Average loss at step ', 46000, ': ', 9.271602244377137)\n",
      "('Average loss at step ', 48000, ': ', 9.271220239162446)\n",
      "('Average loss at step ', 50000, ': ', 9.272343531608582)\n",
      "Nearest to his: her, the, your, patients, number_phrase, and, with, redacted_phrase,\n",
      "Nearest to fluid: destination, nimodipine, source, similar, dht, allow, ep, thrombectomy,\n",
      "Nearest to prior: redacted_phrase, move, bronchoalveolar, number_phrase, outpatient, west, spine, clubbing,\n",
      "Nearest to bp: multiple, anti-inflammatory, u, get, mobilize, reference, cks, normal-appearing,\n",
      "Nearest to patient: she, he, pt, you, hypo, and, to, on,\n",
      "Nearest to /: *, abs, mg, number_phrase, phosphate-, o2, felt, chloride,\n",
      "Nearest to tube: taken, ultrasounds, bright, losses, arthroplasty, compensation, gravity, placement,\n",
      "Nearest to ml: number_phrase, aerosol, tablet, hemorrhagic, gross, 10l, bouts, ezetimibe,\n",
      "Nearest to he: she, patient, you, pt, and, hypo, but, the,\n",
      "Nearest to ct: he, urean-, 1130am, dislocations, 2nd, thrills, sequence, underwent,\n",
      "Nearest to at: on, in, azotemia, UNK, hypo, luminal, number_phrase, and,\n",
      "Nearest to iv: po, number_phrase, click, then, atorvastatin, mcv, combination, smoked,\n",
      "Nearest to daily: qd, *, mg, number_phrase, day, hypo, bid, tid,\n",
      "Nearest to on: and, at, UNK, number_phrase, patient, meq/l, culture-final, to,\n",
      "Nearest to this: the, d/c, thrive, which, it, she, that, questioned,\n",
      "Nearest to is: was, of, has, are, example, redacted_phrase, as, limb,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step ', 52000, ': ', 9.271990392684936)\n",
      "('Average loss at step ', 54000, ': ', 9.27123069190979)\n",
      "('Average loss at step ', 56000, ': ', 9.270753218173981)\n",
      "('Average loss at step ', 58000, ': ', 9.269458838939666)\n",
      "('Average loss at step ', 60000, ': ', 9.268175283432006)\n",
      "Nearest to his: her, your, the, patients, number_phrase, and, with, she,\n",
      "Nearest to fluid: destination, nimodipine, dht, source, similar, thrombectomy, ep, inch,\n",
      "Nearest to prior: move, bronchoalveolar, spine, redacted_phrase, west, clubbing, for, was,\n",
      "Nearest to bp: multiple, anti-inflammatory, u, get, normal-appearing, mobilize, cks, |,\n",
      "Nearest to patient: he, she, pt, you, hypo, and, to, on,\n",
      "Nearest to /: abs, *, mg, phosphate-, chloride, -, felt, o2,\n",
      "Nearest to tube: taken, ultrasounds, bright, compensation, po, arthroplasty, placement, gravity,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, number_phrase, gross, 10l, ezetimibe, opacification,\n",
      "Nearest to he: she, patient, pt, you, and, there, but, hypo,\n",
      "Nearest to ct: he, urean-, 2nd, 1130am, thrills, underwent, sequence, ldlcalc-,\n",
      "Nearest to at: on, number_phrase, in, azotemia, UNK, tablet, hypo, daily,\n",
      "Nearest to iv: po, click, mcv, atorvastatin, levofloxacin, phos-, then, smoked,\n",
      "Nearest to daily: qd, *, day, mg, bid, po, hypo, number_phrase,\n",
      "Nearest to on: and, at, in, UNK, -, to, number_phrase, hypo,\n",
      "Nearest to this: the, that, it, which, d/c, he, she, thrive,\n",
      "Nearest to is: was, has, are, of, example, as, UNK, with,\n",
      "('Average loss at step ', 62000, ': ', 9.269837260246277)\n",
      "('Average loss at step ', 64000, ': ', 9.268927300453186)\n",
      "('Average loss at step ', 66000, ': ', 9.268130995750427)\n",
      "('Average loss at step ', 68000, ': ', 9.26733860683441)\n",
      "('Average loss at step ', 70000, ': ', 9.269121311187744)\n",
      "Nearest to his: her, your, the, patients, redacted_phrase, number_phrase, and, she,\n",
      "Nearest to fluid: destination, source, thrombectomy, dht, nimodipine, similar, ep, allow,\n",
      "Nearest to prior: redacted_phrase, move, bronchoalveolar, for, west, was, spine, beds,\n",
      "Nearest to bp: multiple, anti-inflammatory, u, mobilize, get, |, ast, outlined,\n",
      "Nearest to patient: she, he, pt, you, hypo, to, but, on,\n",
      "Nearest to /: abs, mg, and, *, -, number_phrase, o2, isosorbide,\n",
      "Nearest to tube: taken, placement, bright, ultrasounds, po, gravity, compensation, losses,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, 10l, gross, number_phrase, bouts, opacification,\n",
      "Nearest to he: she, patient, you, pt, the, but, and, hypo,\n",
      "Nearest to ct: he, urean-, 1130am, thrills, 2nd, 1000x, underwent, sequence,\n",
      "Nearest to at: on, UNK, in, azotemia, daily, she, hypo, tablet,\n",
      "Nearest to iv: po, levofloxacin, mcv, 1gm, phos-, click, atorvastatin, porcine,\n",
      "Nearest to daily: qd, *, bid, mg, day, redacted_phrase, hypo, tablet,\n",
      "Nearest to on: at, in, she, UNK, and, to, hypo, number_phrase,\n",
      "Nearest to this: the, which, that, it, redacted_phrase, d/c, she, questioned,\n",
      "Nearest to is: was, has, are, example, of, with, as, UNK,\n",
      "('Average loss at step ', 72000, ': ', 9.26872579240799)\n",
      "('Average loss at step ', 74000, ': ', 9.269373177528381)\n",
      "('Average loss at step ', 76000, ': ', 9.267934133529662)\n",
      "('Average loss at step ', 78000, ': ', 9.267174707889557)\n",
      "('Average loss at step ', 80000, ': ', 9.269120966911316)\n",
      "Nearest to his: her, your, patients, the, number_phrase, and, she, redacted_phrase,\n",
      "Nearest to fluid: destination, similar, thrombectomy, dht, source, nimodipine, blood, allow,\n",
      "Nearest to prior: move, bronchoalveolar, for, west, spine, redacted_phrase, on, bumped,\n",
      "Nearest to bp: anti-inflammatory, multiple, u, outlined, get, ast, normal-appearing, mobilize,\n",
      "Nearest to patient: she, he, pt, you, hypo, but, and, on,\n",
      "Nearest to /: *, abs, mg, o2, -, number_phrase, isosorbide, daily,\n",
      "Nearest to tube: taken, placement, ultrasounds, gravity, bright, compensation, po, sbp160,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, mg, 10l, gross, bouts, hct-,\n",
      "Nearest to he: she, patient, pt, you, but, and, there, hypo,\n",
      "Nearest to ct: urean-, he, 1130am, 2nd, pancreas, underwent, 1000x, impression,\n",
      "Nearest to at: in, on, UNK, hypo, number_phrase, azotemia, daily, tablet,\n",
      "Nearest to iv: po, levofloxacin, mcv, porcine, phos-, then, atorvastatin, 1gm,\n",
      "Nearest to daily: qd, mg, number_phrase, day, *, bid, tablet, po,\n",
      "Nearest to on: number_phrase, at, and, in, UNK, was, hypo, she,\n",
      "Nearest to this: that, which, the, it, d/c, she, job, number_phrase,\n",
      "Nearest to is: was, has, are, of, with, example, as, had,\n",
      "('Average loss at step ', 82000, ': ', 9.26732397556305)\n",
      "('Average loss at step ', 84000, ': ', 9.266691461563111)\n",
      "('Average loss at step ', 86000, ': ', 9.265745344161987)\n",
      "('Average loss at step ', 88000, ': ', 9.264596153736115)\n",
      "('Average loss at step ', 90000, ': ', 9.266682859897614)\n",
      "Nearest to his: her, your, patients, the, number_phrase, and, no, he,\n",
      "Nearest to fluid: source, blood, destination, dht, thrombectomy, similar, nimodipine, allow,\n",
      "Nearest to prior: move, redacted_phrase, on, bronchoalveolar, number_phrase, west, spine, exam,\n",
      "Nearest to bp: anti-inflammatory, cks, multiple, levofloxacin----------, normal-appearing, u, outlined, get,\n",
      "Nearest to patient: she, he, pt, you, hypo, and, po, but,\n",
      "Nearest to /: abs, mg, *, number_phrase, o2, +, -, isosorbide,\n",
      "Nearest to tube: taken, po, placement, ultrasounds, filter, gravity, bright, compensation,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, mg, 10l, gross, banana, one,\n",
      "Nearest to he: she, patient, pt, you, but, and, hypo, the,\n",
      "Nearest to ct: he, urean-, 1130am, 2nd, 1000x, pancreas, impression, underwent,\n",
      "Nearest to at: on, in, UNK, she, hypo, daily, azotemia, tablet,\n",
      "Nearest to iv: po, mcv, then, levofloxacin, atorvastatin, phos-, 1gm, porcine,\n",
      "Nearest to daily: qd, mg, bid, tablet, day, *, hypo, po,\n",
      "Nearest to on: at, number_phrase, UNK, in, he, she, was, and,\n",
      "Nearest to this: that, which, the, it, d/c, she, he, questioned,\n",
      "Nearest to is: was, has, are, example, with, UNK, of, po,\n",
      "('Average loss at step ', 92000, ': ', 9.265799719810486)\n",
      "('Average loss at step ', 94000, ': ', 9.268178621292114)\n",
      "('Average loss at step ', 96000, ': ', 9.263709101200103)\n",
      "('Average loss at step ', 98000, ': ', 9.265431956291199)\n",
      "('Average loss at step ', 100000, ': ', 9.265590295314789)\n",
      "Nearest to his: her, your, patients, the, number_phrase, and, a, redacted_phrase,\n",
      "Nearest to fluid: source, blood, similar, destination, thrombectomy, dht, allow, clavicular,\n",
      "Nearest to prior: after, move, bronchoalveolar, west, bumped, previous, for, old,\n",
      "Nearest to bp: anti-inflammatory, cks, levofloxacin----------, hr, multiple, u, ast, get,\n",
      "Nearest to patient: she, he, pt, you, hypo, and, number_phrase, but,\n",
      "Nearest to /: *, abs, number_phrase, mg, o2, allergies, -, and,\n",
      "Nearest to tube: taken, placement, po, gravity, filter, ultrasounds, pain, bright,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, number_phrase, 10l, mg, one, banana,\n",
      "Nearest to he: she, patient, pt, you, but, and, the, there,\n",
      "Nearest to ct: number_phrase, he, 2nd, underwent, 1130am, urean-, impression, head,\n",
      "Nearest to at: on, in, tablet, hypo, number_phrase, daily, UNK, azotemia,\n",
      "Nearest to iv: po, levofloxacin, then, mcv, 1gm, intravenous, phos-, atorvastatin,\n",
      "Nearest to daily: number_phrase, qd, bid, *, tablet, mg, day, tid,\n",
      "Nearest to on: number_phrase, at, she, and, in, he, hypo, meq/l,\n",
      "Nearest to this: that, which, it, the, d/c, number_phrase, job, her,\n",
      "Nearest to is: was, has, are, of, example, number_phrase, redacted_phrase, had,\n",
      "('Average loss at step ', 102000, ': ', 9.266864396572114)\n",
      "('Average loss at step ', 104000, ': ', 9.262778203964233)\n",
      "('Average loss at step ', 106000, ': ', 9.260337158203125)\n",
      "('Average loss at step ', 108000, ': ', 9.26260014104843)\n",
      "('Average loss at step ', 110000, ': ', 9.261941747188569)\n",
      "Nearest to his: her, your, patients, the, number_phrase, and, a, he,\n",
      "Nearest to fluid: blood, source, destination, thrombectomy, similar, dht, stick, allow,\n",
      "Nearest to prior: after, move, previous, bronchoalveolar, on, west, recent, bumped,\n",
      "Nearest to bp: hr, cks, anti-inflammatory, u, levofloxacin----------, normal-appearing, ast, multiple,\n",
      "Nearest to patient: she, he, pt, you, hypo, UNK, but, patients,\n",
      "Nearest to /: *, abs, o2, number_phrase, mg, and, -, +,\n",
      "Nearest to tube: placement, taken, gravity, po, pain, filter, reoriented, ultrasounds,\n",
      "Nearest to ml: aerosol, tablet, mg, hemorrhagic, number_phrase, 10l, gross, banana,\n",
      "Nearest to he: she, patient, you, pt, but, there, UNK, on,\n",
      "Nearest to ct: 2nd, 1130am, pancreas, head, ears, urean-, scan, impression,\n",
      "Nearest to at: on, in, UNK, tablet, number_phrase, hypo, daily, with,\n",
      "Nearest to iv: po, intravenous, levofloxacin, mcv, 1gm, porcine, phos-, qd,\n",
      "Nearest to daily: qd, po, *, bid, number_phrase, tablet, day, mg,\n",
      "Nearest to on: at, *, he, in, UNK, she, and, number_phrase,\n",
      "Nearest to this: that, which, it, the, d/c, UNK, she, questioned,\n",
      "Nearest to is: was, are, has, UNK, of, *, redacted_phrase, with,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step ', 112000, ': ', 9.263997898578644)\n",
      "('Average loss at step ', 114000, ': ', 9.262927638530732)\n",
      "('Average loss at step ', 116000, ': ', 9.26236762714386)\n",
      "('Average loss at step ', 118000, ': ', 9.264908000469207)\n",
      "('Average loss at step ', 120000, ': ', 9.264458481788635)\n",
      "Nearest to his: her, your, patients, the, number_phrase, and, redacted_phrase, he,\n",
      "Nearest to fluid: source, destination, blood, thrombectomy, similar, trached, dht, stick,\n",
      "Nearest to prior: after, previous, bronchoalveolar, move, recent, redacted_phrase, number_phrase, on,\n",
      "Nearest to bp: hr, number_phrase, cks, anti-inflammatory, u, levofloxacin----------, outlined, normal-appearing,\n",
      "Nearest to patient: he, she, pt, you, hypo, and, patients, to,\n",
      "Nearest to /: abs, number_phrase, *, mg, -, o2, +, and,\n",
      "Nearest to tube: po, taken, placement, gravity, reoriented, filter, thinking, line,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, mg, number_phrase, 10l, inhaler, banana,\n",
      "Nearest to he: she, patient, pt, you, there, and, but, number_phrase,\n",
      "Nearest to ct: he, redacted_phrase, 2nd, UNK, head, 1130am, scan, number_phrase,\n",
      "Nearest to at: on, number_phrase, UNK, in, hypo, daily, he, tablet,\n",
      "Nearest to iv: po, intravenous, levofloxacin, 1gm, number_phrase, mcv, mg, porcine,\n",
      "Nearest to daily: qd, day, bid, number_phrase, mg, po, once, *,\n",
      "Nearest to on: number_phrase, at, in, redacted_phrase, UNK, she, *, and,\n",
      "Nearest to this: that, the, which, it, his, number_phrase, questioned, d/c,\n",
      "Nearest to is: was, has, are, UNK, number_phrase, of, redacted_phrase, example,\n",
      "('Average loss at step ', 122000, ': ', 9.264060961723327)\n",
      "('Average loss at step ', 124000, ': ', 9.262902248382568)\n",
      "('Average loss at step ', 126000, ': ', 9.263451694011689)\n",
      "('Average loss at step ', 128000, ': ', 9.260807003498078)\n",
      "('Average loss at step ', 130000, ': ', 9.262786151885987)\n",
      "Nearest to his: her, your, patients, the, and, a, redacted_phrase, on,\n",
      "Nearest to fluid: thrombectomy, source, destination, similar, trached, dht, sludge, blood,\n",
      "Nearest to prior: after, redacted_phrase, previous, recent, bronchoalveolar, old, move, of,\n",
      "Nearest to bp: hr, cks, anti-inflammatory, u, hematocrit, outlined, levofloxacin----------, normal-appearing,\n",
      "Nearest to patient: she, he, pt, you, hypo, patients, but, redacted_phrase,\n",
      "Nearest to /: abs, -, +, mg, o2, *, number_phrase, and,\n",
      "Nearest to tube: taken, placement, po, line, gravity, pain, compensation, thinking,\n",
      "Nearest to ml: aerosol, tablet, hemorrhagic, mg, inhaler, banana, 10l, gums,\n",
      "Nearest to he: she, patient, pt, you, there, but, and, the,\n",
      "Nearest to ct: redacted_phrase, 2nd, scan, pt, pancreas, impression, head, 1130am,\n",
      "Nearest to at: on, in, UNK, hypo, she, number_phrase, -, daily,\n",
      "Nearest to iv: po, intravenous, levofloxacin, 1gm, mcv, phos-, atorvastatin, porcine,\n",
      "Nearest to daily: qd, bid, number_phrase, po, mg, tid, day, once,\n",
      "Nearest to on: she, number_phrase, in, at, his, he, redacted_phrase, UNK,\n",
      "Nearest to this: that, which, the, it, questioned, his, d/c, there,\n",
      "Nearest to is: was, are, has, of, be, example, -, UNK,\n",
      "('Average loss at step ', 132000, ': ', 9.262151173114777)\n",
      "('Average loss at step ', 134000, ': ', 9.262097602844237)\n",
      "('Average loss at step ', 136000, ': ', 9.263328564167022)\n",
      "('Average loss at step ', 138000, ': ', 9.257441954612732)\n",
      "('Average loss at step ', 140000, ': ', 9.260719513893127)\n",
      "Nearest to his: her, your, patients, the, number_phrase, a, he, on,\n",
      "Nearest to fluid: source, thrombectomy, blood, similar, trached, dht, allow, destination,\n",
      "Nearest to prior: after, previous, number_phrase, redacted_phrase, recent, bronchoalveolar, move, old,\n",
      "Nearest to bp: hr, cks, anti-inflammatory, hematocrit, levofloxacin----------, normal-appearing, outlined, u,\n",
      "Nearest to patient: she, he, pt, patients, you, but, number_phrase, to,\n",
      "Nearest to /: number_phrase, *, abs, mg, +, UNK, and, o2,\n",
      "Nearest to tube: placement, taken, po, line, pain, gravity, number_phrase, filter,\n",
      "Nearest to ml: aerosol, tablet, mg, number_phrase, hemorrhagic, inhaler, banana, 10l,\n",
      "Nearest to he: she, patient, pt, you, there, but, number_phrase, and,\n",
      "Nearest to ct: redacted_phrase, head, pancreas, scan, impression, 1130am, he, 2nd,\n",
      "Nearest to at: on, UNK, in, number_phrase, daily, hypo, redacted_phrase, she,\n",
      "Nearest to iv: po, intravenous, number_phrase, levofloxacin, 1gm, UNK, then, mcv,\n",
      "Nearest to daily: qd, bid, number_phrase, once, day, mg, tablet, *,\n",
      "Nearest to on: number_phrase, UNK, at, in, *, redacted_phrase, his, she,\n",
      "Nearest to this: that, which, the, it, she, he, d/c, questioned,\n",
      "Nearest to is: was, are, has, of, be, example, had, will,\n",
      "('Average loss at step ', 142000, ': ', 9.25978922700882)\n",
      "('Average loss at step ', 144000, ': ', 9.26155150604248)\n",
      "('Average loss at step ', 146000, ': ', 9.261099947929383)\n",
      "('Average loss at step ', 148000, ': ', 9.25803549861908)\n",
      "('Average loss at step ', 150000, ': ', 9.262306074142456)\n",
      "Nearest to his: her, patients, your, the, redacted_phrase, she, no, on,\n",
      "Nearest to fluid: source, blood, thrombectomy, trached, similar, guardian, allow, destination,\n",
      "Nearest to prior: after, redacted_phrase, previous, recent, move, bronchoalveolar, old, last,\n",
      "Nearest to bp: hr, cks, anti-inflammatory, levofloxacin----------, u, outlined, hematocrit, shiley,\n",
      "Nearest to patient: she, he, pt, you, patients, but, hypo, to,\n",
      "Nearest to /: *, abs, -, +, mg, o2, and, pulse,\n",
      "Nearest to tube: placement, taken, pain, line, gravity, thinking, filter, compensation,\n",
      "Nearest to ml: aerosol, tablet, mg, hemorrhagic, number_phrase, 10l, banana, gums,\n",
      "Nearest to he: she, patient, pt, you, there, but, and, UNK,\n",
      "Nearest to ct: he, head, scan, pancreas, pt, impression, 1130am, mri,\n",
      "Nearest to at: in, UNK, on, redacted_phrase, daily, after, hypo, tablet,\n",
      "Nearest to iv: po, intravenous, levofloxacin, 1gm, mcv, qd, phos-, porcine,\n",
      "Nearest to daily: qd, bid, day, mg, once, tid, *, number_phrase,\n",
      "Nearest to on: UNK, in, and, number_phrase, redacted_phrase, qd, his, she,\n",
      "Nearest to this: that, which, it, the, he, redacted_phrase, d/c, her,\n",
      "Nearest to is: was, are, has, redacted_phrase, UNK, of, be, example,\n",
      "('Average loss at step ', 152000, ': ', 9.259745452404022)\n",
      "('Average loss at step ', 154000, ': ', 9.258485809803009)\n",
      "('Average loss at step ', 156000, ': ', 9.259817880630493)\n",
      "('Average loss at step ', 158000, ': ', 9.260398255825043)\n"
     ]
    }
   ],
   "source": [
    "num_steps = 200000\n",
    "nce_start_time = dt.datetime.now()\n",
    "run(graph, num_steps)\n",
    "nce_end_time = dt.datetime.now()\n",
    "print(\"NCE method took {} seconds to run 20000 iterations\".format((nce_end_time-nce_start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
