{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.estimator package not installed.\n",
      "tf.estimator package not installed.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv, re, string, pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': ['as a', 'and a', 'at all', 'aa'],\n",
       " 'ab': ['and by', 'a big', 'a bit', 'ab'],\n",
       " 'ac': ['a couple', 'a child', 'a certain'],\n",
       " 'ad': ['a day', 'and down', 'a drink', 'ad'],\n",
       " 'ae': ['and even', 'anything else', 'an end'],\n",
       " 'af': ['a few', 'and for', 'away from', 'af'],\n",
       " 'ag': ['a good', 'a great', 'a group'],\n",
       " 'ah': ['and he', 'and his', 'as he', 'ah'],\n",
       " 'ai': ['and in', 'and i', 'and it', 'ai'],\n",
       " 'al': ['at least', 'a little', 'a long', 'al'],\n",
       " 'am': ['a man', 'and more', 'a moment', 'am'],\n",
       " 'an': ['a new', 'are not', 'a number', 'an'],\n",
       " 'ao': ['and other', 'all of', 'and of'],\n",
       " 'ap': ['as possible', 'a part', 'a person', 'ap'],\n",
       " 'ar': ['all right', 'a result', 'a real'],\n",
       " 'as': ['a small', 'and said', 'and she', 'as'],\n",
       " 'at': ['and the', 'at the', 'as the', 'at'],\n",
       " 'aw': ['as well', 'and was', 'and with', 'aw'],\n",
       " 'ay': ['a year', 'are you', 'and you'],\n",
       " 'ba': ['by a', 'be a', 'been a', 'ba'],\n",
       " 'bf': ['be found', 'but for', 'been found'],\n",
       " 'bh': ['but he', 'because he', 'behind him', 'bh'],\n",
       " 'bi': ['but it', 'but i', 'but in', 'bi'],\n",
       " 'bm': ['be made', 'been made', 'by means'],\n",
       " 'bn': ['but not', 'be no', 'but no'],\n",
       " 'bo': ['because of', 'based on', 'basis of', 'bo'],\n",
       " 'bs': ['be sure', 'but she', 'be seen', 'bs'],\n",
       " 'bt': ['by the', 'but the', 'between the', 'bt'],\n",
       " 'bw': ['but we', 'but when', 'but what', 'bw'],\n",
       " 'ca': ['called a', 'church and', 'city and', 'ca'],\n",
       " 'cb': ['can be', 'could be', 'cannot be', 'cb'],\n",
       " 'cf': ['come from', 'called for', 'came from', 'cf'],\n",
       " 'ci': ['came in', 'changes in', 'come in'],\n",
       " 'co': ['center of', 'cost of', 'couple of', 'co'],\n",
       " 'ct': ['came to', 'come to', 'close to', 'ct'],\n",
       " 'cw': ['civil war', 'concerned with', 'compared with'],\n",
       " 'da': ['day and', 'down and', 'door and', 'da'],\n",
       " 'di': ['do it', 'does it', 'day in', 'di'],\n",
       " 'dn': ['did not', 'does not', 'do not'],\n",
       " 'do': ['development of', 'department of', 'degree of', 'do'],\n",
       " 'dt': ['during the', 'down the', 'down to'],\n",
       " 'dw': ['do with', 'dealing with', 'deal with', 'dw'],\n",
       " 'dy': ['do you', 'did you', 'dont you'],\n",
       " 'ea': ['even a', 'eyes and', 'economic and'],\n",
       " 'ei': ['even in', 'even if', 'early in'],\n",
       " 'eo': ['end of', 'each other', 'each of', 'eo'],\n",
       " 'es': ['even so', 'ever since', 'ever seen'],\n",
       " 'et': ['enough to', 'even the', 'expected to', 'et'],\n",
       " 'fa': ['for a', 'from a', 'for all'],\n",
       " 'fh': ['for him', 'for his', 'from his'],\n",
       " 'fi': ['for it', 'for instance', 'found in'],\n",
       " 'fm': ['for me', 'for many', 'for more', 'fm'],\n",
       " 'fo': ['front of', 'form of', 'for one'],\n",
       " 'ft': ['for the', 'from the', 'fact that', 'ft'],\n",
       " 'fw': ['for which', 'filled with', 'from which'],\n",
       " 'fy': ['for you', 'fiscal year', 'for years', 'fy'],\n",
       " 'ga': ['get a', 'got a', 'give a', 'ga'],\n",
       " 'go': ['group of', 'government of', 'go on', 'go'],\n",
       " 'gt': ['going to', 'go to', 'get the', 'gt'],\n",
       " 'ha': ['have a', 'had a', 'him and', 'ha'],\n",
       " 'hb': ['had been', 'have been', 'has been'],\n",
       " 'hc': ['he could', 'had come', 'he can'],\n",
       " 'hd': ['he did', 'he didnt', 'he does'],\n",
       " 'he': ['his eyes', 'her eyes', 'had ever', 'he'],\n",
       " 'hf': ['his face', 'he felt', 'his first'],\n",
       " 'hg': ['had gone', 'he got', 'he gave'],\n",
       " 'hh': ['he had', 'he has', 'his head'],\n",
       " 'hi': ['he is', 'him in', 'here in', 'hi'],\n",
       " 'hl': ['his life', 'he looked', 'had left', 'hl'],\n",
       " 'hm': ['his mind', 'he made', 'he must', 'hm'],\n",
       " 'hn': ['had not', 'had no', 'has not'],\n",
       " 'ho': ['his own', 'half of', 'history of'],\n",
       " 'hs': ['he said', 'high school', 'he says'],\n",
       " 'ht': ['had to', 'have to', 'him to'],\n",
       " 'hw': ['he was', 'he would', 'his wife', 'hw'],\n",
       " 'ia': ['in a', 'is a', 'in an'],\n",
       " 'ib': ['i believe', 'in both', 'is being'],\n",
       " 'ic': ['i could', 'i can', 'it can'],\n",
       " 'id': ['i dont', 'it does', 'i do', 'id'],\n",
       " 'ie': ['in each', 'in england', 'in europe', 'ie'],\n",
       " 'if': ['in fact', 'in front', 'in figure', 'if'],\n",
       " 'ig': ['in general', 'i guess', 'i got'],\n",
       " 'ih': ['in his', 'i have', 'i had'],\n",
       " 'ii': ['it is', 'in its', 'is in'],\n",
       " 'ij': ['in june', 'in january', 'is just', 'ij'],\n",
       " 'ik': ['i know', 'i knew', 'is known'],\n",
       " 'il': ['is likely', 'in london', 'in laos', 'il'],\n",
       " 'im': ['in my', 'it may', 'in many', 'im'],\n",
       " 'in': ['is not', 'is no', 'in new', 'in'],\n",
       " 'io': ['in order', 'instead of', 'in our', 'io'],\n",
       " 'ip': ['in place', 'is possible', 'in particular'],\n",
       " 'is': ['i said', 'in some', 'is still', 'is'],\n",
       " 'it': ['in the', 'is the', 'into the', 'it'],\n",
       " 'iw': ['it was', 'in which', 'i was'],\n",
       " 'ko': ['kind of', 'knowledge of', 'kinds of'],\n",
       " 'kt': ['know that', 'knew that', 'know the'],\n",
       " 'la': ['like a', 'look at', 'looked at', 'la'],\n",
       " 'li': ['live in', 'like it', 'life in'],\n",
       " 'lo': ['lack of', 'level of', 'life of', 'lo'],\n",
       " 'lt': ['less than', 'like the', 'like that', 'lt'],\n",
       " 'ma': ['make a', 'made a', 'much as', 'ma'],\n",
       " 'mb': ['may be', 'must be', 'might be'],\n",
       " 'mh': ['must have', 'may have', 'might have'],\n",
       " 'mi': ['make it', 'made in', 'man in', 'mi'],\n",
       " 'mo': ['most of', 'members of', 'many of', 'mo'],\n",
       " 'mt': ['more than', 'me to', 'make the', 'mt'],\n",
       " 'mw': ['man who', 'men who', 'man with'],\n",
       " 'na': ['not a', 'now and', 'not as', 'na'],\n",
       " 'nb': ['not be', 'not been', 'nothing but'],\n",
       " 'nm': ['no more', 'no matter', 'next morning', 'nm'],\n",
       " 'no': ['number of', 'not only', 'no one', 'no'],\n",
       " 'nt': ['not to', 'not the', 'necessary to'],\n",
       " 'oa': ['of a', 'on a', 'of all'],\n",
       " 'ob': ['of being', 'only by', 'of both', 'ob'],\n",
       " 'oc': ['of course', 'of christ', 'of commerce'],\n",
       " 'od': ['one day', 'on december', 'of death'],\n",
       " 'oe': ['or even', 'of each', 'of europe'],\n",
       " 'of': ['of fact', 'out for', 'or for', 'of'],\n",
       " 'og': ['of god', 'of government', 'of great'],\n",
       " 'oh': ['of his', 'of her', 'on his', 'oh'],\n",
       " 'oi': ['of it', 'of its', 'on it'],\n",
       " 'oj': ['on january', 'on june', 'on july'],\n",
       " 'ol': ['of life', 'or less', 'of literature', 'ol'],\n",
       " 'om': ['of my', 'of men', 'or more'],\n",
       " 'on': ['of new', 'or not', 'on november', 'on'],\n",
       " 'oo': ['one of', 'out of', 'of our'],\n",
       " 'op': ['of people', 'other people', 'of power', 'op'],\n",
       " 'os': ['of such', 'of state', 'of some', 'os'],\n",
       " 'ot': ['of the', 'on the', 'of this'],\n",
       " 'ow': ['of which', 'of what', 'of water'],\n",
       " 'oy': ['of your', 'of you', 'of years'],\n",
       " 'pa': ['people and', 'power and', 'put a', 'pa'],\n",
       " 'pi': ['place in', 'published in', 'put it', 'pi'],\n",
       " 'po': ['part of', 'period of', 'point of', 'po'],\n",
       " 'pt': ['possible to', 'prior to', 'put the', 'pt'],\n",
       " 'ra': ['research and', 'room and', 'regarded as', 'ra'],\n",
       " 'rf': ['responsibility for', 'reason for', 'responsible for', 'rf'],\n",
       " 'ro': ['rate of', 'rest of', 'result of'],\n",
       " 'rt': ['rather than', 'right to', 'ready to'],\n",
       " 'sa': ['such a', 'such as', 'states and'],\n",
       " 'sb': ['should be', 'shall be', 'small business'],\n",
       " 'sc': ['she could', 'see chapter', 'supreme court', 'sc'],\n",
       " 'sd': ['sat down', 'she did', 'she didnt', 'sd'],\n",
       " 'sf': ['so far', 'san francisco', 'search for'],\n",
       " 'sh': ['she had', 'said he', 'should have', 'sh'],\n",
       " 'si': ['said i', 'shown in', 'said it', 'si'],\n",
       " 'sl': ['so long', 'st louis', 'she looked', 'sl'],\n",
       " 'so': ['some of', 'sense of', 'side of', 'so'],\n",
       " 'st': ['so that', 'since the', 'seemed to', 'st'],\n",
       " 'su': ['set up', 'stood up', 'soviet union'],\n",
       " 'sw': ['she was', 'she would', 'same way', 'sw'],\n",
       " 'sy': ['said you', 'so you', 'see you'],\n",
       " 'ta': ['to a', 'they are', 'there are'],\n",
       " 'tb': ['to be', 'the best', 'the back', 'tb'],\n",
       " 'tc': ['the church', 'the city', 'the country'],\n",
       " 'td': ['to do', 'the door', 'the day'],\n",
       " 'te': ['the end', 'the entire', 'the earth'],\n",
       " 'tf': ['the first', 'the fact', 'to find'],\n",
       " 'tg': ['to get', 'to go', 'the great'],\n",
       " 'th': ['that he', 'to have', 'to his', 'th'],\n",
       " 'ti': ['there is', 'this is', 'that is', 'ti'],\n",
       " 'tj': ['the job', 'the jury', 'to join'],\n",
       " 'tk': ['to keep', 'to know', 'the kitchen'],\n",
       " 'tl': ['the last', 'the latter', 'the light'],\n",
       " 'tm': ['the most', 'to make', 'to me'],\n",
       " 'tn': ['the new', 'the next', 'the number'],\n",
       " 'to': ['the other', 'the only', 'the old', 'to'],\n",
       " 'tp': ['the past', 'the president', 'the public'],\n",
       " 'tr': ['the right', 'the road', 'the rest', 'tr'],\n",
       " 'ts': ['the same', 'the state', 'to see', 'ts'],\n",
       " 'tt': ['to the', 'that the', 'through the', 'tt'],\n",
       " 'tu': ['the united', 'the use', 'the university'],\n",
       " 'tv': ['the very', 'the various', 'the valley', 'tv'],\n",
       " 'tw': ['there was', 'the world', 'they were', 'tw'],\n",
       " 'ty': ['the year', 'to you', 'the young'],\n",
       " 'ua': ['up and', 'up a', 'under a'],\n",
       " 'uf': ['used for', 'up for', 'up from'],\n",
       " 'ui': ['up in', 'used in', 'use it', 'ui'],\n",
       " 'uo': ['use of', 'university of', 'up on'],\n",
       " 'ut': ['up to', 'up the', 'under the'],\n",
       " 'vo': ['value of', 'variety of', 'view of'],\n",
       " 'wa': ['with a', 'was a', 'well as'],\n",
       " 'wb': ['would be', 'will be', 'was born'],\n",
       " 'wc': ['we can', 'was called', 'we could'],\n",
       " 'wd': ['we do', 'washington dc', 'would do'],\n",
       " 'wf': ['waiting for', 'was found', 'we find'],\n",
       " 'wg': ['was going', 'was gone', 'were going', 'wg'],\n",
       " 'wh': ['when he', 'would have', 'we have', 'wh'],\n",
       " 'wi': ['which is', 'was in', 'what is'],\n",
       " 'wm': ['with me', 'we must', 'was made', 'wm'],\n",
       " 'wn': ['was not', 'was no', 'would not'],\n",
       " 'wo': ['went on', 'way of', 'was one'],\n",
       " 'ws': ['was still', 'when she', 'was so', 'ws'],\n",
       " 'wt': ['with the', 'was the', 'when the', 'wt'],\n",
       " 'ww': ['world war', 'which was', 'who was'],\n",
       " 'wy': ['when you', 'with you', 'what you'],\n",
       " 'ya': ['years ago', 'you are', 'you and', 'ya'],\n",
       " 'yc': ['you can', 'you could', 'york city', 'yc'],\n",
       " 'yh': ['you have', 'you he', 'you had'],\n",
       " 'yi': ['years in', 'you i', 'year in'],\n",
       " 'ym': ['you may', 'young man', 'young men', 'ym'],\n",
       " 'yo': ['years of', 'years old', 'your own'],\n",
       " 'ys': ['you say', 'you see', 'you should', 'ys'],\n",
       " 'yt': ['you to', 'years the', 'you think', 'yt'],\n",
       " 'yw': ['you will', 'you want', 'you were']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('acros_brown.pickle', 'rb') as handle:\n",
    "    acro_dct = pickle.load(handle)\n",
    "\n",
    "acro_dct = {k:[' '.join(x) for x in v] for k,v in acro_dct.items()}\n",
    "acro_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acro_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a', 'big'): 'ab',\n",
       " ('a', 'bit'): 'ab',\n",
       " ('a', 'certain'): 'ac',\n",
       " ('a', 'child'): 'ac',\n",
       " ('a', 'couple'): 'ac',\n",
       " ('a', 'day'): 'ad',\n",
       " ('a', 'drink'): 'ad',\n",
       " ('a', 'few'): 'af',\n",
       " ('a', 'good'): 'ag',\n",
       " ('a', 'great'): 'ag',\n",
       " ('a', 'group'): 'ag',\n",
       " ('a', 'little'): 'al',\n",
       " ('a', 'long'): 'al',\n",
       " ('a', 'man'): 'am',\n",
       " ('a', 'moment'): 'am',\n",
       " ('a', 'new'): 'an',\n",
       " ('a', 'number'): 'an',\n",
       " ('a', 'part'): 'ap',\n",
       " ('a', 'person'): 'ap',\n",
       " ('a', 'real'): 'ar',\n",
       " ('a', 'result'): 'ar',\n",
       " ('a', 'small'): 'as',\n",
       " ('a', 'year'): 'ay',\n",
       " ('aa',): 'aa',\n",
       " ('ab',): 'ab',\n",
       " ('ad',): 'ad',\n",
       " ('af',): 'af',\n",
       " ('ah',): 'ah',\n",
       " ('ai',): 'ai',\n",
       " ('al',): 'al',\n",
       " ('all', 'of'): 'ao',\n",
       " ('all', 'right'): 'ar',\n",
       " ('am',): 'am',\n",
       " ('an',): 'an',\n",
       " ('an', 'end'): 'ae',\n",
       " ('and', 'a'): 'aa',\n",
       " ('and', 'by'): 'ab',\n",
       " ('and', 'down'): 'ad',\n",
       " ('and', 'even'): 'ae',\n",
       " ('and', 'for'): 'af',\n",
       " ('and', 'he'): 'ah',\n",
       " ('and', 'his'): 'ah',\n",
       " ('and', 'i'): 'ai',\n",
       " ('and', 'in'): 'ai',\n",
       " ('and', 'it'): 'ai',\n",
       " ('and', 'more'): 'am',\n",
       " ('and', 'of'): 'ao',\n",
       " ('and', 'other'): 'ao',\n",
       " ('and', 'said'): 'as',\n",
       " ('and', 'she'): 'as',\n",
       " ('and', 'the'): 'at',\n",
       " ('and', 'was'): 'aw',\n",
       " ('and', 'with'): 'aw',\n",
       " ('and', 'you'): 'ay',\n",
       " ('anything', 'else'): 'ae',\n",
       " ('ap',): 'ap',\n",
       " ('are', 'not'): 'an',\n",
       " ('are', 'you'): 'ay',\n",
       " ('as',): 'as',\n",
       " ('as', 'a'): 'aa',\n",
       " ('as', 'he'): 'ah',\n",
       " ('as', 'possible'): 'ap',\n",
       " ('as', 'the'): 'at',\n",
       " ('as', 'well'): 'aw',\n",
       " ('at',): 'at',\n",
       " ('at', 'all'): 'aa',\n",
       " ('at', 'least'): 'al',\n",
       " ('at', 'the'): 'at',\n",
       " ('aw',): 'aw',\n",
       " ('away', 'from'): 'af',\n",
       " ('ba',): 'ba',\n",
       " ('based', 'on'): 'bo',\n",
       " ('basis', 'of'): 'bo',\n",
       " ('be', 'a'): 'ba',\n",
       " ('be', 'found'): 'bf',\n",
       " ('be', 'made'): 'bm',\n",
       " ('be', 'no'): 'bn',\n",
       " ('be', 'seen'): 'bs',\n",
       " ('be', 'sure'): 'bs',\n",
       " ('because', 'he'): 'bh',\n",
       " ('because', 'of'): 'bo',\n",
       " ('been', 'a'): 'ba',\n",
       " ('been', 'found'): 'bf',\n",
       " ('been', 'made'): 'bm',\n",
       " ('behind', 'him'): 'bh',\n",
       " ('between', 'the'): 'bt',\n",
       " ('bh',): 'bh',\n",
       " ('bi',): 'bi',\n",
       " ('bo',): 'bo',\n",
       " ('bs',): 'bs',\n",
       " ('bt',): 'bt',\n",
       " ('but', 'for'): 'bf',\n",
       " ('but', 'he'): 'bh',\n",
       " ('but', 'i'): 'bi',\n",
       " ('but', 'in'): 'bi',\n",
       " ('but', 'it'): 'bi',\n",
       " ('but', 'no'): 'bn',\n",
       " ('but', 'not'): 'bn',\n",
       " ('but', 'she'): 'bs',\n",
       " ('but', 'the'): 'bt',\n",
       " ('but', 'we'): 'bw',\n",
       " ('but', 'what'): 'bw',\n",
       " ('but', 'when'): 'bw',\n",
       " ('bw',): 'bw',\n",
       " ('by', 'a'): 'ba',\n",
       " ('by', 'means'): 'bm',\n",
       " ('by', 'the'): 'bt',\n",
       " ('ca',): 'ca',\n",
       " ('called', 'a'): 'ca',\n",
       " ('called', 'for'): 'cf',\n",
       " ('came', 'from'): 'cf',\n",
       " ('came', 'in'): 'ci',\n",
       " ('came', 'to'): 'ct',\n",
       " ('can', 'be'): 'cb',\n",
       " ('cannot', 'be'): 'cb',\n",
       " ('cb',): 'cb',\n",
       " ('center', 'of'): 'co',\n",
       " ('cf',): 'cf',\n",
       " ('changes', 'in'): 'ci',\n",
       " ('church', 'and'): 'ca',\n",
       " ('city', 'and'): 'ca',\n",
       " ('civil', 'war'): 'cw',\n",
       " ('close', 'to'): 'ct',\n",
       " ('co',): 'co',\n",
       " ('come', 'from'): 'cf',\n",
       " ('come', 'in'): 'ci',\n",
       " ('come', 'to'): 'ct',\n",
       " ('compared', 'with'): 'cw',\n",
       " ('concerned', 'with'): 'cw',\n",
       " ('cost', 'of'): 'co',\n",
       " ('could', 'be'): 'cb',\n",
       " ('couple', 'of'): 'co',\n",
       " ('ct',): 'ct',\n",
       " ('da',): 'da',\n",
       " ('day', 'and'): 'da',\n",
       " ('day', 'in'): 'di',\n",
       " ('deal', 'with'): 'dw',\n",
       " ('dealing', 'with'): 'dw',\n",
       " ('degree', 'of'): 'do',\n",
       " ('department', 'of'): 'do',\n",
       " ('development', 'of'): 'do',\n",
       " ('di',): 'di',\n",
       " ('did', 'not'): 'dn',\n",
       " ('did', 'you'): 'dy',\n",
       " ('do',): 'do',\n",
       " ('do', 'it'): 'di',\n",
       " ('do', 'not'): 'dn',\n",
       " ('do', 'with'): 'dw',\n",
       " ('do', 'you'): 'dy',\n",
       " ('does', 'it'): 'di',\n",
       " ('does', 'not'): 'dn',\n",
       " ('dont', 'you'): 'dy',\n",
       " ('door', 'and'): 'da',\n",
       " ('down', 'and'): 'da',\n",
       " ('down', 'the'): 'dt',\n",
       " ('down', 'to'): 'dt',\n",
       " ('during', 'the'): 'dt',\n",
       " ('dw',): 'dw',\n",
       " ('each', 'of'): 'eo',\n",
       " ('each', 'other'): 'eo',\n",
       " ('early', 'in'): 'ei',\n",
       " ('economic', 'and'): 'ea',\n",
       " ('end', 'of'): 'eo',\n",
       " ('enough', 'to'): 'et',\n",
       " ('eo',): 'eo',\n",
       " ('et',): 'et',\n",
       " ('even', 'a'): 'ea',\n",
       " ('even', 'if'): 'ei',\n",
       " ('even', 'in'): 'ei',\n",
       " ('even', 'so'): 'es',\n",
       " ('even', 'the'): 'et',\n",
       " ('ever', 'seen'): 'es',\n",
       " ('ever', 'since'): 'es',\n",
       " ('expected', 'to'): 'et',\n",
       " ('eyes', 'and'): 'ea',\n",
       " ('fact', 'that'): 'ft',\n",
       " ('filled', 'with'): 'fw',\n",
       " ('fiscal', 'year'): 'fy',\n",
       " ('fm',): 'fm',\n",
       " ('for', 'a'): 'fa',\n",
       " ('for', 'all'): 'fa',\n",
       " ('for', 'him'): 'fh',\n",
       " ('for', 'his'): 'fh',\n",
       " ('for', 'instance'): 'fi',\n",
       " ('for', 'it'): 'fi',\n",
       " ('for', 'many'): 'fm',\n",
       " ('for', 'me'): 'fm',\n",
       " ('for', 'more'): 'fm',\n",
       " ('for', 'one'): 'fo',\n",
       " ('for', 'the'): 'ft',\n",
       " ('for', 'which'): 'fw',\n",
       " ('for', 'years'): 'fy',\n",
       " ('for', 'you'): 'fy',\n",
       " ('form', 'of'): 'fo',\n",
       " ('found', 'in'): 'fi',\n",
       " ('from', 'a'): 'fa',\n",
       " ('from', 'his'): 'fh',\n",
       " ('from', 'the'): 'ft',\n",
       " ('from', 'which'): 'fw',\n",
       " ('front', 'of'): 'fo',\n",
       " ('ft',): 'ft',\n",
       " ('fy',): 'fy',\n",
       " ('ga',): 'ga',\n",
       " ('get', 'a'): 'ga',\n",
       " ('get', 'the'): 'gt',\n",
       " ('give', 'a'): 'ga',\n",
       " ('go',): 'go',\n",
       " ('go', 'on'): 'go',\n",
       " ('go', 'to'): 'gt',\n",
       " ('going', 'to'): 'gt',\n",
       " ('got', 'a'): 'ga',\n",
       " ('government', 'of'): 'go',\n",
       " ('group', 'of'): 'go',\n",
       " ('gt',): 'gt',\n",
       " ('ha',): 'ha',\n",
       " ('had', 'a'): 'ha',\n",
       " ('had', 'been'): 'hb',\n",
       " ('had', 'come'): 'hc',\n",
       " ('had', 'ever'): 'he',\n",
       " ('had', 'gone'): 'hg',\n",
       " ('had', 'left'): 'hl',\n",
       " ('had', 'no'): 'hn',\n",
       " ('had', 'not'): 'hn',\n",
       " ('had', 'to'): 'ht',\n",
       " ('half', 'of'): 'ho',\n",
       " ('has', 'been'): 'hb',\n",
       " ('has', 'not'): 'hn',\n",
       " ('have', 'a'): 'ha',\n",
       " ('have', 'been'): 'hb',\n",
       " ('have', 'to'): 'ht',\n",
       " ('he',): 'he',\n",
       " ('he', 'can'): 'hc',\n",
       " ('he', 'could'): 'hc',\n",
       " ('he', 'did'): 'hd',\n",
       " ('he', 'didnt'): 'hd',\n",
       " ('he', 'does'): 'hd',\n",
       " ('he', 'felt'): 'hf',\n",
       " ('he', 'gave'): 'hg',\n",
       " ('he', 'got'): 'hg',\n",
       " ('he', 'had'): 'hh',\n",
       " ('he', 'has'): 'hh',\n",
       " ('he', 'is'): 'hi',\n",
       " ('he', 'looked'): 'hl',\n",
       " ('he', 'made'): 'hm',\n",
       " ('he', 'must'): 'hm',\n",
       " ('he', 'said'): 'hs',\n",
       " ('he', 'says'): 'hs',\n",
       " ('he', 'was'): 'hw',\n",
       " ('he', 'would'): 'hw',\n",
       " ('her', 'eyes'): 'he',\n",
       " ('here', 'in'): 'hi',\n",
       " ('hi',): 'hi',\n",
       " ('high', 'school'): 'hs',\n",
       " ('him', 'and'): 'ha',\n",
       " ('him', 'in'): 'hi',\n",
       " ('him', 'to'): 'ht',\n",
       " ('his', 'eyes'): 'he',\n",
       " ('his', 'face'): 'hf',\n",
       " ('his', 'first'): 'hf',\n",
       " ('his', 'head'): 'hh',\n",
       " ('his', 'life'): 'hl',\n",
       " ('his', 'mind'): 'hm',\n",
       " ('his', 'own'): 'ho',\n",
       " ('his', 'wife'): 'hw',\n",
       " ('history', 'of'): 'ho',\n",
       " ('hl',): 'hl',\n",
       " ('hm',): 'hm',\n",
       " ('hw',): 'hw',\n",
       " ('i', 'believe'): 'ib',\n",
       " ('i', 'can'): 'ic',\n",
       " ('i', 'could'): 'ic',\n",
       " ('i', 'do'): 'id',\n",
       " ('i', 'dont'): 'id',\n",
       " ('i', 'got'): 'ig',\n",
       " ('i', 'guess'): 'ig',\n",
       " ('i', 'had'): 'ih',\n",
       " ('i', 'have'): 'ih',\n",
       " ('i', 'knew'): 'ik',\n",
       " ('i', 'know'): 'ik',\n",
       " ('i', 'said'): 'is',\n",
       " ('i', 'was'): 'iw',\n",
       " ('id',): 'id',\n",
       " ('ie',): 'ie',\n",
       " ('if',): 'if',\n",
       " ('ij',): 'ij',\n",
       " ('il',): 'il',\n",
       " ('im',): 'im',\n",
       " ('in',): 'in',\n",
       " ('in', 'a'): 'ia',\n",
       " ('in', 'an'): 'ia',\n",
       " ('in', 'both'): 'ib',\n",
       " ('in', 'each'): 'ie',\n",
       " ('in', 'england'): 'ie',\n",
       " ('in', 'europe'): 'ie',\n",
       " ('in', 'fact'): 'if',\n",
       " ('in', 'figure'): 'if',\n",
       " ('in', 'front'): 'if',\n",
       " ('in', 'general'): 'ig',\n",
       " ('in', 'his'): 'ih',\n",
       " ('in', 'its'): 'ii',\n",
       " ('in', 'january'): 'ij',\n",
       " ('in', 'june'): 'ij',\n",
       " ('in', 'laos'): 'il',\n",
       " ('in', 'london'): 'il',\n",
       " ('in', 'many'): 'im',\n",
       " ('in', 'my'): 'im',\n",
       " ('in', 'new'): 'in',\n",
       " ('in', 'order'): 'io',\n",
       " ('in', 'our'): 'io',\n",
       " ('in', 'particular'): 'ip',\n",
       " ('in', 'place'): 'ip',\n",
       " ('in', 'some'): 'is',\n",
       " ('in', 'the'): 'it',\n",
       " ('in', 'which'): 'iw',\n",
       " ('instead', 'of'): 'io',\n",
       " ('into', 'the'): 'it',\n",
       " ('io',): 'io',\n",
       " ('is',): 'is',\n",
       " ('is', 'a'): 'ia',\n",
       " ('is', 'being'): 'ib',\n",
       " ('is', 'in'): 'ii',\n",
       " ('is', 'just'): 'ij',\n",
       " ('is', 'known'): 'ik',\n",
       " ('is', 'likely'): 'il',\n",
       " ('is', 'no'): 'in',\n",
       " ('is', 'not'): 'in',\n",
       " ('is', 'possible'): 'ip',\n",
       " ('is', 'still'): 'is',\n",
       " ('is', 'the'): 'it',\n",
       " ('it',): 'it',\n",
       " ('it', 'can'): 'ic',\n",
       " ('it', 'does'): 'id',\n",
       " ('it', 'is'): 'ii',\n",
       " ('it', 'may'): 'im',\n",
       " ('it', 'was'): 'iw',\n",
       " ('kind', 'of'): 'ko',\n",
       " ('kinds', 'of'): 'ko',\n",
       " ('knew', 'that'): 'kt',\n",
       " ('know', 'that'): 'kt',\n",
       " ('know', 'the'): 'kt',\n",
       " ('knowledge', 'of'): 'ko',\n",
       " ('la',): 'la',\n",
       " ('lack', 'of'): 'lo',\n",
       " ('less', 'than'): 'lt',\n",
       " ('level', 'of'): 'lo',\n",
       " ('life', 'in'): 'li',\n",
       " ('life', 'of'): 'lo',\n",
       " ('like', 'a'): 'la',\n",
       " ('like', 'it'): 'li',\n",
       " ('like', 'that'): 'lt',\n",
       " ('like', 'the'): 'lt',\n",
       " ('live', 'in'): 'li',\n",
       " ('lo',): 'lo',\n",
       " ('look', 'at'): 'la',\n",
       " ('looked', 'at'): 'la',\n",
       " ('lt',): 'lt',\n",
       " ('ma',): 'ma',\n",
       " ('made', 'a'): 'ma',\n",
       " ('made', 'in'): 'mi',\n",
       " ('make', 'a'): 'ma',\n",
       " ('make', 'it'): 'mi',\n",
       " ('make', 'the'): 'mt',\n",
       " ('man', 'in'): 'mi',\n",
       " ('man', 'who'): 'mw',\n",
       " ('man', 'with'): 'mw',\n",
       " ('many', 'of'): 'mo',\n",
       " ('may', 'be'): 'mb',\n",
       " ('may', 'have'): 'mh',\n",
       " ('me', 'to'): 'mt',\n",
       " ('members', 'of'): 'mo',\n",
       " ('men', 'who'): 'mw',\n",
       " ('mi',): 'mi',\n",
       " ('might', 'be'): 'mb',\n",
       " ('might', 'have'): 'mh',\n",
       " ('mo',): 'mo',\n",
       " ('more', 'than'): 'mt',\n",
       " ('most', 'of'): 'mo',\n",
       " ('mt',): 'mt',\n",
       " ('much', 'as'): 'ma',\n",
       " ('must', 'be'): 'mb',\n",
       " ('must', 'have'): 'mh',\n",
       " ('na',): 'na',\n",
       " ('necessary', 'to'): 'nt',\n",
       " ('next', 'morning'): 'nm',\n",
       " ('nm',): 'nm',\n",
       " ('no',): 'no',\n",
       " ('no', 'matter'): 'nm',\n",
       " ('no', 'more'): 'nm',\n",
       " ('no', 'one'): 'no',\n",
       " ('not', 'a'): 'na',\n",
       " ('not', 'as'): 'na',\n",
       " ('not', 'be'): 'nb',\n",
       " ('not', 'been'): 'nb',\n",
       " ('not', 'only'): 'no',\n",
       " ('not', 'the'): 'nt',\n",
       " ('not', 'to'): 'nt',\n",
       " ('nothing', 'but'): 'nb',\n",
       " ('now', 'and'): 'na',\n",
       " ('number', 'of'): 'no',\n",
       " ('ob',): 'ob',\n",
       " ('of',): 'of',\n",
       " ('of', 'a'): 'oa',\n",
       " ('of', 'all'): 'oa',\n",
       " ('of', 'being'): 'ob',\n",
       " ('of', 'both'): 'ob',\n",
       " ('of', 'christ'): 'oc',\n",
       " ('of', 'commerce'): 'oc',\n",
       " ('of', 'course'): 'oc',\n",
       " ('of', 'death'): 'od',\n",
       " ('of', 'each'): 'oe',\n",
       " ('of', 'europe'): 'oe',\n",
       " ('of', 'fact'): 'of',\n",
       " ('of', 'god'): 'og',\n",
       " ('of', 'government'): 'og',\n",
       " ('of', 'great'): 'og',\n",
       " ('of', 'her'): 'oh',\n",
       " ('of', 'his'): 'oh',\n",
       " ('of', 'it'): 'oi',\n",
       " ('of', 'its'): 'oi',\n",
       " ('of', 'life'): 'ol',\n",
       " ('of', 'literature'): 'ol',\n",
       " ('of', 'men'): 'om',\n",
       " ('of', 'my'): 'om',\n",
       " ('of', 'new'): 'on',\n",
       " ('of', 'our'): 'oo',\n",
       " ('of', 'people'): 'op',\n",
       " ('of', 'power'): 'op',\n",
       " ('of', 'some'): 'os',\n",
       " ('of', 'state'): 'os',\n",
       " ('of', 'such'): 'os',\n",
       " ('of', 'the'): 'ot',\n",
       " ('of', 'this'): 'ot',\n",
       " ('of', 'water'): 'ow',\n",
       " ('of', 'what'): 'ow',\n",
       " ('of', 'which'): 'ow',\n",
       " ('of', 'years'): 'oy',\n",
       " ('of', 'you'): 'oy',\n",
       " ('of', 'your'): 'oy',\n",
       " ('oh',): 'oh',\n",
       " ('ol',): 'ol',\n",
       " ('on',): 'on',\n",
       " ('on', 'a'): 'oa',\n",
       " ('on', 'december'): 'od',\n",
       " ('on', 'his'): 'oh',\n",
       " ('on', 'it'): 'oi',\n",
       " ('on', 'january'): 'oj',\n",
       " ('on', 'july'): 'oj',\n",
       " ('on', 'june'): 'oj',\n",
       " ('on', 'november'): 'on',\n",
       " ('on', 'the'): 'ot',\n",
       " ('one', 'day'): 'od',\n",
       " ('one', 'of'): 'oo',\n",
       " ('only', 'by'): 'ob',\n",
       " ('op',): 'op',\n",
       " ('or', 'even'): 'oe',\n",
       " ('or', 'for'): 'of',\n",
       " ('or', 'less'): 'ol',\n",
       " ('or', 'more'): 'om',\n",
       " ('or', 'not'): 'on',\n",
       " ('os',): 'os',\n",
       " ('other', 'people'): 'op',\n",
       " ('out', 'for'): 'of',\n",
       " ('out', 'of'): 'oo',\n",
       " ('pa',): 'pa',\n",
       " ('part', 'of'): 'po',\n",
       " ('people', 'and'): 'pa',\n",
       " ('period', 'of'): 'po',\n",
       " ('pi',): 'pi',\n",
       " ('place', 'in'): 'pi',\n",
       " ('po',): 'po',\n",
       " ('point', 'of'): 'po',\n",
       " ('possible', 'to'): 'pt',\n",
       " ('power', 'and'): 'pa',\n",
       " ('prior', 'to'): 'pt',\n",
       " ('pt',): 'pt',\n",
       " ('published', 'in'): 'pi',\n",
       " ('put', 'a'): 'pa',\n",
       " ('put', 'it'): 'pi',\n",
       " ('put', 'the'): 'pt',\n",
       " ('ra',): 'ra',\n",
       " ('rate', 'of'): 'ro',\n",
       " ('rather', 'than'): 'rt',\n",
       " ('ready', 'to'): 'rt',\n",
       " ('reason', 'for'): 'rf',\n",
       " ('regarded', 'as'): 'ra',\n",
       " ('research', 'and'): 'ra',\n",
       " ('responsibility', 'for'): 'rf',\n",
       " ('responsible', 'for'): 'rf',\n",
       " ('rest', 'of'): 'ro',\n",
       " ('result', 'of'): 'ro',\n",
       " ('rf',): 'rf',\n",
       " ('right', 'to'): 'rt',\n",
       " ('room', 'and'): 'ra',\n",
       " ('said', 'he'): 'sh',\n",
       " ('said', 'i'): 'si',\n",
       " ('said', 'it'): 'si',\n",
       " ('said', 'you'): 'sy',\n",
       " ('same', 'way'): 'sw',\n",
       " ('san', 'francisco'): 'sf',\n",
       " ('sat', 'down'): 'sd',\n",
       " ('sc',): 'sc',\n",
       " ('sd',): 'sd',\n",
       " ('search', 'for'): 'sf',\n",
       " ('see', 'chapter'): 'sc',\n",
       " ('see', 'you'): 'sy',\n",
       " ('seemed', 'to'): 'st',\n",
       " ('sense', 'of'): 'so',\n",
       " ('set', 'up'): 'su',\n",
       " ('sh',): 'sh',\n",
       " ('shall', 'be'): 'sb',\n",
       " ('she', 'could'): 'sc',\n",
       " ('she', 'did'): 'sd',\n",
       " ('she', 'didnt'): 'sd',\n",
       " ('she', 'had'): 'sh',\n",
       " ('she', 'looked'): 'sl',\n",
       " ('she', 'was'): 'sw',\n",
       " ('she', 'would'): 'sw',\n",
       " ('should', 'be'): 'sb',\n",
       " ('should', 'have'): 'sh',\n",
       " ('shown', 'in'): 'si',\n",
       " ('si',): 'si',\n",
       " ('side', 'of'): 'so',\n",
       " ('since', 'the'): 'st',\n",
       " ('sl',): 'sl',\n",
       " ('small', 'business'): 'sb',\n",
       " ('so',): 'so',\n",
       " ('so', 'far'): 'sf',\n",
       " ('so', 'long'): 'sl',\n",
       " ('so', 'that'): 'st',\n",
       " ('so', 'you'): 'sy',\n",
       " ('some', 'of'): 'so',\n",
       " ('soviet', 'union'): 'su',\n",
       " ('st',): 'st',\n",
       " ('st', 'louis'): 'sl',\n",
       " ('states', 'and'): 'sa',\n",
       " ('stood', 'up'): 'su',\n",
       " ('such', 'a'): 'sa',\n",
       " ('such', 'as'): 'sa',\n",
       " ('supreme', 'court'): 'sc',\n",
       " ('sw',): 'sw',\n",
       " ('tb',): 'tb',\n",
       " ('th',): 'th',\n",
       " ('that', 'he'): 'th',\n",
       " ('that', 'is'): 'ti',\n",
       " ('that', 'the'): 'tt',\n",
       " ('the', 'back'): 'tb',\n",
       " ('the', 'best'): 'tb',\n",
       " ('the', 'church'): 'tc',\n",
       " ('the', 'city'): 'tc',\n",
       " ('the', 'country'): 'tc',\n",
       " ('the', 'day'): 'td',\n",
       " ('the', 'door'): 'td',\n",
       " ('the', 'earth'): 'te',\n",
       " ('the', 'end'): 'te',\n",
       " ('the', 'entire'): 'te',\n",
       " ('the', 'fact'): 'tf',\n",
       " ('the', 'first'): 'tf',\n",
       " ('the', 'great'): 'tg',\n",
       " ('the', 'job'): 'tj',\n",
       " ('the', 'jury'): 'tj',\n",
       " ('the', 'kitchen'): 'tk',\n",
       " ('the', 'last'): 'tl',\n",
       " ('the', 'latter'): 'tl',\n",
       " ('the', 'light'): 'tl',\n",
       " ('the', 'most'): 'tm',\n",
       " ('the', 'new'): 'tn',\n",
       " ('the', 'next'): 'tn',\n",
       " ('the', 'number'): 'tn',\n",
       " ('the', 'old'): 'to',\n",
       " ('the', 'only'): 'to',\n",
       " ('the', 'other'): 'to',\n",
       " ('the', 'past'): 'tp',\n",
       " ('the', 'president'): 'tp',\n",
       " ('the', 'public'): 'tp',\n",
       " ('the', 'rest'): 'tr',\n",
       " ('the', 'right'): 'tr',\n",
       " ('the', 'road'): 'tr',\n",
       " ('the', 'same'): 'ts',\n",
       " ('the', 'state'): 'ts',\n",
       " ('the', 'united'): 'tu',\n",
       " ('the', 'university'): 'tu',\n",
       " ('the', 'use'): 'tu',\n",
       " ('the', 'valley'): 'tv',\n",
       " ('the', 'various'): 'tv',\n",
       " ('the', 'very'): 'tv',\n",
       " ('the', 'world'): 'tw',\n",
       " ('the', 'year'): 'ty',\n",
       " ('the', 'young'): 'ty',\n",
       " ('there', 'are'): 'ta',\n",
       " ('there', 'is'): 'ti',\n",
       " ('there', 'was'): 'tw',\n",
       " ('they', 'are'): 'ta',\n",
       " ('they', 'were'): 'tw',\n",
       " ('this', 'is'): 'ti',\n",
       " ('through', 'the'): 'tt',\n",
       " ('ti',): 'ti',\n",
       " ('to',): 'to',\n",
       " ('to', 'a'): 'ta',\n",
       " ('to', 'be'): 'tb',\n",
       " ('to', 'do'): 'td',\n",
       " ('to', 'find'): 'tf',\n",
       " ('to', 'get'): 'tg',\n",
       " ('to', 'go'): 'tg',\n",
       " ('to', 'have'): 'th',\n",
       " ('to', 'his'): 'th',\n",
       " ('to', 'join'): 'tj',\n",
       " ('to', 'keep'): 'tk',\n",
       " ('to', 'know'): 'tk',\n",
       " ('to', 'make'): 'tm',\n",
       " ('to', 'me'): 'tm',\n",
       " ('to', 'see'): 'ts',\n",
       " ('to', 'the'): 'tt',\n",
       " ('to', 'you'): 'ty',\n",
       " ('tr',): 'tr',\n",
       " ('ts',): 'ts',\n",
       " ('tt',): 'tt',\n",
       " ('tv',): 'tv',\n",
       " ('tw',): 'tw',\n",
       " ('ui',): 'ui',\n",
       " ('under', 'a'): 'ua',\n",
       " ('under', 'the'): 'ut',\n",
       " ('university', 'of'): 'uo',\n",
       " ('up', 'a'): 'ua',\n",
       " ('up', 'and'): 'ua',\n",
       " ('up', 'for'): 'uf',\n",
       " ('up', 'from'): 'uf',\n",
       " ('up', 'in'): 'ui',\n",
       " ('up', 'on'): 'uo',\n",
       " ('up', 'the'): 'ut',\n",
       " ('up', 'to'): 'ut',\n",
       " ('use', 'it'): 'ui',\n",
       " ('use', 'of'): 'uo',\n",
       " ('used', 'for'): 'uf',\n",
       " ('used', 'in'): 'ui',\n",
       " ('value', 'of'): 'vo',\n",
       " ('variety', 'of'): 'vo',\n",
       " ('view', 'of'): 'vo',\n",
       " ('waiting', 'for'): 'wf',\n",
       " ('was', 'a'): 'wa',\n",
       " ('was', 'born'): 'wb',\n",
       " ('was', 'called'): 'wc',\n",
       " ('was', 'found'): 'wf',\n",
       " ('was', 'going'): 'wg',\n",
       " ('was', 'gone'): 'wg',\n",
       " ('was', 'in'): 'wi',\n",
       " ('was', 'made'): 'wm',\n",
       " ('was', 'no'): 'wn',\n",
       " ('was', 'not'): 'wn',\n",
       " ('was', 'one'): 'wo',\n",
       " ('was', 'so'): 'ws',\n",
       " ('was', 'still'): 'ws',\n",
       " ('was', 'the'): 'wt',\n",
       " ('washington', 'dc'): 'wd',\n",
       " ('way', 'of'): 'wo',\n",
       " ('we', 'can'): 'wc',\n",
       " ('we', 'could'): 'wc',\n",
       " ('we', 'do'): 'wd',\n",
       " ('we', 'find'): 'wf',\n",
       " ('we', 'have'): 'wh',\n",
       " ('we', 'must'): 'wm',\n",
       " ('well', 'as'): 'wa',\n",
       " ('went', 'on'): 'wo',\n",
       " ('were', 'going'): 'wg',\n",
       " ('wg',): 'wg',\n",
       " ('wh',): 'wh',\n",
       " ('what', 'is'): 'wi',\n",
       " ('what', 'you'): 'wy',\n",
       " ('when', 'he'): 'wh',\n",
       " ('when', 'she'): 'ws',\n",
       " ('when', 'the'): 'wt',\n",
       " ('when', 'you'): 'wy',\n",
       " ('which', 'is'): 'wi',\n",
       " ('which', 'was'): 'ww',\n",
       " ('who', 'was'): 'ww',\n",
       " ('will', 'be'): 'wb',\n",
       " ('with', 'a'): 'wa',\n",
       " ('with', 'me'): 'wm',\n",
       " ('with', 'the'): 'wt',\n",
       " ('with', 'you'): 'wy',\n",
       " ('wm',): 'wm',\n",
       " ('world', 'war'): 'ww',\n",
       " ('would', 'be'): 'wb',\n",
       " ('would', 'do'): 'wd',\n",
       " ('would', 'have'): 'wh',\n",
       " ('would', 'not'): 'wn',\n",
       " ('ws',): 'ws',\n",
       " ('wt',): 'wt',\n",
       " ('ya',): 'ya',\n",
       " ('yc',): 'yc',\n",
       " ('year', 'in'): 'yi',\n",
       " ('years', 'ago'): 'ya',\n",
       " ('years', 'in'): 'yi',\n",
       " ('years', 'of'): 'yo',\n",
       " ('years', 'old'): 'yo',\n",
       " ('years', 'the'): 'yt',\n",
       " ('ym',): 'ym',\n",
       " ('york', 'city'): 'yc',\n",
       " ('you', 'and'): 'ya',\n",
       " ('you', 'are'): 'ya',\n",
       " ('you', 'can'): 'yc',\n",
       " ('you', 'could'): 'yc',\n",
       " ('you', 'had'): 'yh',\n",
       " ('you', 'have'): 'yh',\n",
       " ('you', 'he'): 'yh',\n",
       " ('you', 'i'): 'yi',\n",
       " ('you', 'may'): 'ym',\n",
       " ('you', 'say'): 'ys',\n",
       " ('you', 'see'): 'ys',\n",
       " ('you', 'should'): 'ys',\n",
       " ('you', 'think'): 'yt',\n",
       " ('you', 'to'): 'yt',\n",
       " ('you', 'want'): 'yw',\n",
       " ('you', 'were'): 'yw',\n",
       " ('you', 'will'): 'yw',\n",
       " ('young', 'man'): 'ym',\n",
       " ('young', 'men'): 'ym',\n",
       " ('your', 'own'): 'yo',\n",
       " ('ys',): 'ys',\n",
       " ('yt',): 'yt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_acro_dct = {}\n",
    "for key, acros in acro_dct.items():\n",
    "    for acro in acros:\n",
    "        inverted_acro_dct[tuple(acro.split())] = key\n",
    "inverted_acro_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile='/home/rishubj/text/brown-data/cleaned_brown_acro_data.csv'\n",
    "cleaned = pd.read_csv(dfile, header=None).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishubj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('the fulton county grand jury said friday an investigation of atlantas recent primary election produc',\n",
       " 'us from what iw able to gauge ia swift greedy glance the figure inside the coralcolored boucle dress')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.ix[0,0][:100], cleaned.ix[0,0][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words = [word for word in sent.split() for sent in cleaned.iloc[:,0] if len(word)>0]\n",
    "all_words = [word for sent in cleaned.iloc[:,0] for word in sent.split() if len(word)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896353"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [['UNK', -1]]\n",
    "counter = collections.Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896353"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 506)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "all_words_in_acro_dct = []\n",
    "\n",
    "for word in acro_dct:\n",
    "    if word in counter:\n",
    "        all_words_in_acro_dct.append(word)\n",
    "        all_words_in_acro_dct.extend([word for sent in acro_dct[word] for word in sent.split() if len(word)>0])\n",
    "        i+=1\n",
    "all_words_in_acro_dct = set(all_words_in_acro_dct)\n",
    "print(i, len(all_words_in_acro_dct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# real version:\n",
    "def build_dataset(all_words, lines, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    b=counter.most_common(n_words)\n",
    "    c=set(zip(*b)[0])\n",
    "    print (len(c), len(c-all_words_in_acro_dct))\n",
    "    # add 1 to all\n",
    "    for word in c-all_words_in_acro_dct:\n",
    "        count.append([word, counter[word]+1])\n",
    "    for word in all_words_in_acro_dct:\n",
    "        if word not in counter:\n",
    "            val = 1\n",
    "        else:\n",
    "            val = counter[word]+1\n",
    "        count.append([word, val])\n",
    "            \n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    print (\"made vocabulary\")\n",
    "    data = list()\n",
    "    unk_count = 1 # add 1 to all\n",
    "    for word in all_words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    \n",
    "#     acro_dct_num = {}\n",
    "#     for word in all_words_in_acro_dct:\n",
    "#         defins = acro_dct[word]\n",
    "#         acro_dct_num[dictionary[word]] = [[dictionary[w] for w in sent.split() if len(w)>0] for sent in defins]\n",
    "    return data, count, dictionary, reversed_dictionary #, acro_dct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9497)\n",
      "made vocabulary\n"
     ]
    }
   ],
   "source": [
    "base_vocabulary_size = 10000\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(all_words, cleaned.iloc[:,0], base_vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acro_dct_num = {}\n",
    "for word, defins in acro_dct.items():\n",
    "    if word in counter:\n",
    "        acro_dct_num[dictionary[word]] = [[dictionary[w] for w in sent.split() if len(w)>0] for sent in defins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 205, 205)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary), len(acro_dct_num), len(acro_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=all_words_in_acro_dct-set(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46375, [('the', 30574), ('and', 22340), ('of', 17520)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter), counter.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 9501)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[acro_dct.keys()[-1]], dictionary[acro_dct.keys()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {3: 50364, 4: 139509})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jcounts = collections.defaultdict(int)\n",
    "for j in data:\n",
    "    if j in acro_dct_num:\n",
    "        jcounts[len(acro_dct_num[j])]+=1\n",
    "jcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {3: 101, 4: 104}), 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcounts = collections.defaultdict(int)\n",
    "k=0\n",
    "l=0\n",
    "for i,j in acro_dct.items():\n",
    "    rcounts[len(j)]+=1\n",
    "    if len(j)==1:\n",
    "        k+=1\n",
    "#         print (i,j)\n",
    "        if i==j[0]:\n",
    "            l+=1\n",
    "            print (i,j)\n",
    "    if len(j)>=5:\n",
    "        print (i,j)\n",
    "rcounts, k, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_index = 0\n",
    "# generate batch data\n",
    "def generate_batch(data, batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "    buff = collections.deque(maxlen=span)\n",
    "    \n",
    "    acro_data = []\n",
    "    \n",
    "    for _ in range(span):\n",
    "        # TODO: make function:\n",
    "        next_data = data[data_index]\n",
    "        if (next_data in acro_dct_num):\n",
    "            bef = data[data_index-2*skip_window:data_index]\n",
    "            aft = data[data_index+1:data_index+2*skip_window+1]\n",
    "            acro_replacements = [bef+mid+aft for mid in acro_dct_num[next_data]]\n",
    "            acro_data.append(acro_replacements)\n",
    "        buff.append(next_data)\n",
    "            \n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # input word at the center of the buff\n",
    "        targets_to_avoid = [skip_window]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buff[skip_window]  # this is the input word\n",
    "            context[i * num_skips + j, 0] = buff[target]  # these are the context words\n",
    "            \n",
    "        # TODO: make function:\n",
    "        next_data = data[data_index]\n",
    "        if (next_data in acro_dct_num):\n",
    "            bef = data[data_index-2*skip_window:data_index]\n",
    "            aft = data[data_index+1:data_index+2*skip_window+1]\n",
    "            acro_replacements = [bef+mid+aft for mid in acro_dct_num[next_data]]\n",
    "            acro_data.append(acro_replacements)\n",
    "        buff.append(next_data)\n",
    "            \n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, context, acro_data\n",
    "\n",
    "\n",
    "def generate_batch_from_acro_data(acro_data, batch_size, skip_window):\n",
    "    data_index = 0 # this is a local variable\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "    \n",
    "    global_low = 2*skip_window\n",
    "    global_high = len(acro_data)-2*skip_window - 1\n",
    "    for i in range(batch_size):\n",
    "        mid = data_index + skip_window  # input word at the center of the buff\n",
    "        if mid >= global_low and mid <= global_high:\n",
    "            low = data_index\n",
    "            high = data_index + 2*skip_window\n",
    "        else:\n",
    "            low = max(global_low, data_index)\n",
    "            high = min(global_high, data_index + 2*skip_window)\n",
    "            \n",
    "        target = mid\n",
    "        targets_to_avoid = [target]\n",
    "        while target in targets_to_avoid:\n",
    "            target = random.randint(low, high)\n",
    "            \n",
    "        batch[i] = acro_data[mid]  # this is the input word\n",
    "        context[i, 0] = acro_data[target]  # these are the context words\n",
    "        \n",
    "        data_index+=1\n",
    "        if data_index >= len(acro_data) - 2*skip_window:\n",
    "            data_index = 0\n",
    "            \n",
    "        \n",
    "    return batch, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([202, 203, 204, 205, 206, 207, 202, 203, 204, 205], dtype=int32),\n",
       " array([[204],\n",
       "        [204],\n",
       "        [203],\n",
       "        [206],\n",
       "        [204],\n",
       "        [205],\n",
       "        [204],\n",
       "        [204],\n",
       "        [202],\n",
       "        [203]], dtype=int32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_window=2\n",
    "data_index=0\n",
    "batch_size=10\n",
    "acro_data = np.arange(10)+200\n",
    "generate_batch_from_acro_data(acro_data, batch_size, skip_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected data\n"
     ]
    }
   ],
   "source": [
    "print (\"collected data\")\n",
    "batch_size = 128\n",
    "acro_batch_size = 32\n",
    "embedding_size = 150  # Dimension of the embedding vector.\n",
    "skip_window = 2       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_context = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    train_acro_inputs = tf.placeholder(tf.int32, shape=[None, acro_batch_size])\n",
    "    train_acro_context = tf.placeholder(tf.int32, shape=[None, acro_batch_size, 1])\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "            tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "    acro_embed = tf.nn.embedding_lookup(embeddings, train_acro_inputs)\n",
    "\n",
    "    \n",
    "    \n",
    "    # SOFTMAX ***************\n",
    "    \n",
    "    # Construct the variables for the softmax\n",
    "    weights = tf.Variable(\n",
    "            tf.truncated_normal([embedding_size, vocabulary_size],\n",
    "                                                    stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    hidden_out = tf.transpose(tf.matmul(tf.transpose(weights), tf.transpose(embed))) + biases\n",
    "\n",
    "    # convert train_context to a one-hot format\n",
    "    train_one_hot = tf.one_hot(train_context, vocabulary_size)\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=hidden_out, \n",
    "            labels=train_one_hot))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def softmax_loss_loop(labels=train_context, inputs=embed):\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=tf.transpose(tf.matmul(tf.transpose(weights), \n",
    "                                              tf.transpose(inputs))) + biases, \n",
    "                labels=tf.one_hot(labels, vocabulary_size)))\n",
    "    \n",
    "    softmax_mapped = tf.map_fn(lambda x: softmax_loss_loop(x[0], x[1]), \n",
    "                       (train_acro_context,acro_embed), \n",
    "                       dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    acro_softmax_loss = tf.reduce_min(softmax_mapped)\n",
    "    best_softmax_acro_chosen = tf.argmin(softmax_mapped)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "#     softmax_optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(cross_entropy)\n",
    "    softmax_optimizer = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "    acro_softmax_optimizer = tf.train.GradientDescentOptimizer(.01).minimize(acro_softmax_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # SOFTMAX ***************\n",
    "    \n",
    "    \n",
    "    \n",
    "    # VALIDATION:\n",
    "    \n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(\n",
    "            normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "            valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# num_steps = 100\n",
    "# softmax_start_time = dt.datetime.now()\n",
    "# run(graph, num_steps=num_steps)\n",
    "# softmax_end_time = dt.datetime.now()\n",
    "# print(\"Softmax method took {} minutes to run 100 iterations\".format((softmax_end_time-softmax_start_time).total_seconds()))\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Construct the variables for the NCE loss\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    nce_loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(weights=nce_weights,\n",
    "                       biases=nce_biases,\n",
    "                       labels=train_context,\n",
    "                       inputs=embed,\n",
    "                       num_sampled=num_sampled,\n",
    "                       num_classes=vocabulary_size))\n",
    "    \n",
    "    def nce_loss_loop(labels=train_context, inputs=embed):\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.nce_loss(weights=nce_weights,\n",
    "                           biases=nce_biases,\n",
    "                           labels=labels,\n",
    "                           inputs=inputs,\n",
    "                           num_sampled=num_sampled,\n",
    "                           num_classes=vocabulary_size))\n",
    "    \n",
    "    mapped = tf.map_fn(lambda x: nce_loss_loop(x[0], x[1]), (train_acro_context,acro_embed), dtype=tf.float32)\n",
    "    \n",
    "    acro_nce_loss = tf.reduce_min(mapped)\n",
    "    best_acro_chosen = tf.argmin(mapped)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(nce_loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(nce_loss)\n",
    "    acro_optimizer = tf.train.GradientDescentOptimizer(.01).minimize(acro_nce_loss)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile='/home/rishubj/text/brown-data/cleaned_brown_data.csv'\n",
    "original_data = pd.read_csv(dfile, header=None).dropna()\n",
    "\n",
    "with open('replaced.pickle', 'rb') as handle:\n",
    "    replaced = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_all_words = [word for sent in original_data.iloc[:,0] for word in sent.split() if len(word)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_acro_data(session, data_word):\n",
    "    acro_batch_inputs = []\n",
    "    acro_batch_context = []\n",
    "    for single_acro_data in data_word:\n",
    "        a,b = generate_batch_from_acro_data(single_acro_data,\n",
    "                acro_batch_size, skip_window)\n",
    "        acro_batch_inputs.append(a)\n",
    "        acro_batch_context.append(b)\n",
    "    acro_feed_dict = {train_acro_inputs: acro_batch_inputs, train_acro_context: acro_batch_context}\n",
    "\n",
    "    best_acro = session.run(best_acro_chosen, feed_dict=acro_feed_dict)\n",
    "    return best_acro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(session, num_test_samples=100, verbose=False):\n",
    "    chosen_keys = np.random.choice(replaced.keys(), num_test_samples, replace=False)\n",
    "    num_correct=0\n",
    "    tot_choices = 0\n",
    "    for key in chosen_keys:\n",
    "        # key is the word after the correct acronym\n",
    "        bef = [( dictionary[word] if word in dictionary else 0) \n",
    "               for word in original_all_words[key-skip_window-2*skip_window:key-skip_window]]\n",
    "        aft = [( dictionary[word] if word in dictionary else 0) \n",
    "               for word in original_all_words[key:key+2*skip_window]]\n",
    "        acr = inverted_acro_dct[replaced[key]]\n",
    "        correct_acro = ' '.join(original_all_words[key-skip_window:key])\n",
    "        correct_acro_ind = acro_dct[inverted_acro_dct[replaced[key]]].index(correct_acro)\n",
    "\n",
    "        data_word = [bef+mid+aft for mid in acro_dct_num[dictionary[inverted_acro_dct[replaced[key]]]]]\n",
    "        pred_acro=run_test_acro_data(session, data_word)\n",
    "\n",
    "        if verbose:\n",
    "            print (key, pred_acro, correct_acro, correct_acro_ind)\n",
    "        if pred_acro == correct_acro_ind:\n",
    "            num_correct += 1\n",
    "        tot_choices += len(acro_dct[acr])\n",
    "    print (\"Accuracy with {} examples: {}. Expected acc: {}\".format(\n",
    "        num_test_samples, num_correct *1.0 / num_test_samples, num_test_samples * 1.0 / tot_choices))\n",
    "    return num_correct *1.0 / num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# includes acro_data        \n",
    "def run(graph, num_steps, prefix='', start_step = 0):\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver = tf.train.Saver() \n",
    "        # We must initialize all variables before we use them.\n",
    "        if start_step>0:\n",
    "            saver.restore(session, '/home/rishubj/text/code/chkp/'+prefix+'model-final.chkp')\n",
    "        else:\n",
    "            init.run()\n",
    "        print('Initialized')\n",
    "\n",
    "        average_loss = 0\n",
    "        acro_average_loss = 0\n",
    "        valid_acc=[]\n",
    "        main_losses=[]\n",
    "        acro_losses=[]\n",
    "        for step in range(start_step, start_step+num_steps):\n",
    "            batch_inputs, batch_context, acro_data = generate_batch(data,\n",
    "                    batch_size, num_skips, skip_window)\n",
    "            \n",
    "            \n",
    "            \n",
    "            feed_dict = {train_inputs: batch_inputs, train_context: batch_context}\n",
    "\n",
    "            # We perform one update step by evaluating the optimizer op (including it\n",
    "            # in the list of returned values for session.run()\n",
    "            _, loss_val = session.run([optimizer, nce_loss], feed_dict=feed_dict)\n",
    "            average_loss += loss_val\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Now, redo it for acronyms:\n",
    "            for data_word in acro_data:\n",
    "                acro_batch_inputs = []\n",
    "                acro_batch_context = []\n",
    "                for single_acro_data in data_word:\n",
    "                    a,b = generate_batch_from_acro_data(single_acro_data,\n",
    "                            acro_batch_size, skip_window)\n",
    "                    acro_batch_inputs.append(a)\n",
    "                    acro_batch_context.append(b)\n",
    "                acro_feed_dict = {train_acro_inputs: acro_batch_inputs, train_acro_context: acro_batch_context}\n",
    "                _, acro_loss_val = session.run([acro_optimizer, acro_nce_loss], feed_dict=acro_feed_dict)\n",
    "                acro_average_loss += acro_loss_val\n",
    "\n",
    "            \n",
    "            \n",
    "            if step % 2000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 2000\n",
    "                    acro_average_loss /= 2000\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "                print('Average regular loss at step ', step, ': ', average_loss)\n",
    "                print('Average acro loss at step ', step, ': ', acro_average_loss)\n",
    "                main_losses.append(average_loss)\n",
    "                acro_losses.append(acro_average_loss)\n",
    "                average_loss = 0\n",
    "                acro_average_loss = 0\n",
    "                \n",
    "                valid_acc.append(validate(session))\n",
    "                \n",
    "                saver.save(session, '/home/rishubj/text/code/chkp/'+prefix+'model-step-{}.chkp'.format(step))\n",
    "\n",
    "            # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                    top_k = 8  # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log_str = 'Nearest to %s:' % valid_word\n",
    "#                     print (len(nearest), sim.shape, nearest, sim)\n",
    "                    for k in range(top_k):\n",
    "                        close_word = reverse_dictionary[nearest[k]]\n",
    "                        log_str = '%s %s,' % (log_str, close_word)\n",
    "                    print(log_str)\n",
    "        final_embeddings = normalized_embeddings.eval()\n",
    "        saver.save(session, '/home/rishubj/text/code/chkp/'+prefix+'model-final.chkp')\n",
    "        \n",
    "    with open('acro_losses.pickle', 'wb') as handle:\n",
    "        pickle.dump(acro_losses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('main_losses.pickle', 'wb') as handle:\n",
    "        pickle.dump(main_losses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    return valid_acc, main_losses, acro_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "('Average regular loss at step ', 0, ': ', 254.74740600585938)\n",
      "('Average acro loss at step ', 0, ': ', 3217.026901245117)\n",
      "Accuracy with 100 examples: 0.24. Expected acc: 0.280898876404\n",
      "Nearest to reports: hardsurface, boxes, trucks, defend, jastrow, beloved, attractive, fellow,\n",
      "Nearest to criticism: mysterious, likelihood, fighter, relish, pouring, zen, bronx, present,\n",
      "Nearest to owed: schweitzer, exports, pour, fiat, occur, ahead, involve, ws,\n",
      "Nearest to contributes: stem, swiss, utilized, export, paso, ringing, seventeen, traffic,\n",
      "Nearest to spoke: creed, solving, ancestry, races, astonishing, pitcher, heed, respond,\n",
      "Nearest to opponents: qualities, went, clamped, involution, liberalism, possible, neat, barbecue,\n",
      "Nearest to tires: portrait, sort, wax, adds, warmth, duplication, effort, distinguish,\n",
      "Nearest to degreesf: post, motions, cm, gaiety, settle, train, cracking, pratt,\n",
      "Nearest to reporter: versus, tan, sinister, insistence, literally, retreat, participated, anxiety,\n",
      "Nearest to UNK: involve, ay, happiness, pole, sets, eloquent, inning, virtue,\n",
      "Nearest to military: shopping, foolish, obey, density, child, fo, singled, detected,\n",
      "Nearest to errors: insight, heads, driving, ardent, allow, supporting, images, perspective,\n",
      "Nearest to protestants: aide, comprised, framed, conversely, inquiry, bounce, scholarly, hub,\n",
      "Nearest to music: carpet, watch, efficacy, wished, levels, brandt, electric, subsystems,\n",
      "Nearest to succession: poet, accommodate, parochial, acquisition, indictment, likelihood, salesman, citizens,\n",
      "Nearest to writings: accomplishments, persian, operates, practical, dreamed, marys, belong, churchs,\n",
      "('Average regular loss at step ', 2000, ': ', 75.3745334057808)\n",
      "('Average acro loss at step ', 2000, ': ', 819.247316359289)\n",
      "Accuracy with 100 examples: 0.35. Expected acc: 0.285714285714\n",
      "('Average regular loss at step ', 4000, ': ', 22.452176976919173)\n",
      "('Average acro loss at step ', 4000, ': ', 179.74483673899994)\n",
      "Accuracy with 100 examples: 0.31. Expected acc: 0.290697674419\n",
      "('Average regular loss at step ', 6000, ': ', 10.38271323609352)\n",
      "('Average acro loss at step ', 6000, ': ', 76.0574335298501)\n",
      "Accuracy with 100 examples: 0.31. Expected acc: 0.28818443804\n",
      "('Average regular loss at step ', 8000, ': ', 7.339272443056107)\n",
      "('Average acro loss at step ', 8000, ': ', 47.70536991671659)\n",
      "Accuracy with 100 examples: 0.2. Expected acc: 0.28328611898\n",
      "('Average regular loss at step ', 10000, ': ', 5.826741394877434)\n",
      "('Average acro loss at step ', 10000, ': ', 33.67632073523477)\n",
      "Accuracy with 100 examples: 0.3. Expected acc: 0.289855072464\n",
      "Nearest to reports: attractive, trucks, carry, fellow, military, shot, henry, variety,\n",
      "Nearest to criticism: mysterious, present, tc, likelihood, edge, again, nation, extraordinary,\n",
      "Nearest to owed: occur, ws, involve, ahead, month, blind, woman, played,\n",
      "Nearest to contributes: stem, traffic, does, fingers, cw, ra, presentation, distinct,\n",
      "Nearest to spoke: share, behavior, different, cycle, teacher, doctors, security, income,\n",
      "Nearest to opponents: qualities, went, possible, touch, means, liberalism, older, looks,\n",
      "Nearest to tires: sort, portrait, effort, half, wish, warmth, sw, distinguish,\n",
      "Nearest to degreesf: post, train, cm, settle, varied, ive, failing, notice,\n",
      "Nearest to reporter: anxiety, literally, versus, participated, reasonably, insistence, sinister, efficiency,\n",
      "Nearest to UNK: if, for, it, no, more, of, on, aa,\n",
      "Nearest to military: child, department, ic, fo, density, assembly, strategy, reports,\n",
      "Nearest to errors: insight, driving, main, allow, well, heads, supporting, perspective,\n",
      "Nearest to protestants: comprised, aide, inquiry, insisted, precious, earths, conversely, dark,\n",
      "Nearest to music: watch, electric, last, campaign, levels, wished, russian, wonder,\n",
      "Nearest to succession: poet, citizens, accommodate, returned, sent, op, attitude, third,\n",
      "Nearest to writings: belong, practical, got, according, difficulty, principles, conducted, understand,\n",
      "NCE method took 762.976807 seconds to run 11000 iterations\n"
     ]
    }
   ],
   "source": [
    "num_steps = 11000\n",
    "prefix = 'brown-steps-{}-'.format(num_steps)\n",
    "nce_start_time = dt.datetime.now()\n",
    "valid_acc, main_losses, acro_losses = run(graph, num_steps, prefix=prefix)\n",
    "nce_end_time = dt.datetime.now()\n",
    "print(\"NCE method took {} seconds to run {} iterations\".format(\n",
    "    (nce_end_time-nce_start_time).total_seconds(), num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4eef63b190>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4eef490350>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(main_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4eef7337d0>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acro_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/rishubj/text/code/chkp/brown-steps-11000-model-final.chkp\n",
      "Initialized\n",
      "('Average regular loss at step ', 12000, ': ', 2.342118669450283)\n",
      "('Average acro loss at step ', 12000, ': ', 10.863835813660174)\n",
      "Accuracy with 100 examples: 0.25. Expected acc: 0.280112044818\n",
      "('Average regular loss at step ', 14000, ': ', 4.2740382409691815)\n",
      "('Average acro loss at step ', 14000, ': ', 18.306369212143125)\n",
      "Accuracy with 100 examples: 0.36. Expected acc: 0.2849002849\n",
      "NCE method took 334.125396 seconds to run 5000 iterations\n"
     ]
    }
   ],
   "source": [
    "num_steps = 5000\n",
    "prefix = 'brown-steps-{}-'.format(11000)\n",
    "nce_start_time = dt.datetime.now()\n",
    "valid_acc, main_losses, acro_losses = run(graph, num_steps, prefix=prefix, start_step = 11000)\n",
    "nce_end_time = dt.datetime.now()\n",
    "print(\"NCE method took {} seconds to run {} iterations\".format(\n",
    "    (nce_end_time-nce_start_time).total_seconds(), num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(valid_acc)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(main_losses)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(acro_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vA, vB):\n",
    "    return np.dot(vA, vB) / (np.sqrt(np.dot(vA,vA)) * np.sqrt(np.dot(vB,vB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/rishubj/text/code/chkp/brown-steps-11000-model-final.chkp\n",
      "(153141, 3, 'and the', 0)\n",
      "(625290, 2, 'for a', 0)\n",
      "(306793, 3, 'and a', 1)\n",
      "(830755, 2, 'it was', 0)\n",
      "(687423, 1, 'in an', 2)\n",
      "(315107, 1, 'and down', 1)\n",
      "(690023, 2, 'as the', 2)\n",
      "(123137, 2, 'to the', 0)\n",
      "(797825, 0, 'of his', 0)\n",
      "(507277, 0, 'it is', 0)\n",
      "(345282, 1, 'and in', 0)\n",
      "(853615, 1, 'a few', 0)\n",
      "(162408, 1, 'to make', 1)\n",
      "(370969, 2, 'of a', 0)\n",
      "(408626, 2, 'as well', 0)\n",
      "(406400, 2, 'in the', 0)\n",
      "(929896, 1, 'in his', 0)\n",
      "(188038, 1, 'a man', 0)\n",
      "(904738, 1, 'i could', 0)\n",
      "(576493, 2, 'to be', 0)\n",
      "(669386, 2, 'to a', 0)\n",
      "(790576, 1, 'of the', 0)\n",
      "(945706, 3, 'instead of', 1)\n",
      "(28463, 2, 'to a', 0)\n",
      "(842784, 2, 'to see', 2)\n",
      "(921214, 3, 'in the', 0)\n",
      "(853358, 2, 'and i', 1)\n",
      "(948282, 1, 'he could', 0)\n",
      "(760508, 2, 'to see', 2)\n",
      "(460042, 2, 'with the', 0)\n",
      "(384449, 1, 'we must', 1)\n",
      "(374760, 0, 'they are', 1)\n",
      "(39314, 1, 'she had', 0)\n",
      "(757695, 2, 'the church', 0)\n",
      "(945848, 3, 'the world', 1)\n",
      "(274410, 3, 'basis of', 2)\n",
      "(617456, 1, 'for the', 0)\n",
      "(179204, 2, 'this is', 1)\n",
      "(496291, 2, 'on the', 1)\n",
      "(215795, 3, 'in our', 2)\n",
      "(66684, 3, 'for the', 0)\n",
      "(860502, 0, 'of the', 0)\n",
      "(257710, 2, 'so that', 0)\n",
      "(906896, 2, 'and i', 1)\n",
      "(526035, 0, 'the most', 0)\n",
      "(410145, 0, 'he has', 1)\n",
      "(124249, 1, 'by the', 0)\n",
      "(565079, 3, 'in the', 0)\n",
      "(502923, 3, 'to the', 0)\n",
      "(632562, 0, 'on the', 1)\n",
      "(649542, 0, 'of the', 0)\n",
      "(469015, 3, 'there is', 0)\n",
      "(568043, 1, 'must be', 1)\n",
      "(1003031, 1, 'as the', 2)\n",
      "(308938, 0, 'such a', 0)\n",
      "(167433, 0, 'in a', 0)\n",
      "(301177, 2, 'years ago', 0)\n",
      "(461586, 1, 'there was', 0)\n",
      "(346744, 1, 'in an', 2)\n",
      "(296407, 1, 'does not', 1)\n",
      "(343452, 1, 'to a', 0)\n",
      "(191287, 0, 'on the', 1)\n",
      "(665029, 2, 'of a', 0)\n",
      "(142400, 0, 'he has', 1)\n",
      "(205969, 2, 'down to', 2)\n",
      "(1000103, 2, 'in a', 0)\n",
      "(808218, 2, 'of her', 1)\n",
      "(591685, 1, 'like the', 1)\n",
      "(955064, 2, 'of water', 2)\n",
      "(47759, 2, 'in a', 0)\n",
      "(980026, 2, 'i knew', 1)\n",
      "(478309, 0, 'in the', 0)\n",
      "(814110, 0, 'on a', 1)\n",
      "(456634, 0, 'found in', 2)\n",
      "(850372, 0, 'city and', 2)\n",
      "(522748, 0, 'under the', 2)\n",
      "(920432, 0, 'into the', 2)\n",
      "(987256, 1, 'of the', 0)\n",
      "(411514, 1, 'may be', 0)\n",
      "(779001, 0, 'in his', 0)\n",
      "(799624, 0, 'and it', 2)\n",
      "(627653, 2, 'what is', 2)\n",
      "(499949, 1, 'a little', 1)\n",
      "(253754, 2, 'for which', 0)\n",
      "(970294, 1, 'with a', 0)\n",
      "(777277, 1, 'i dont', 0)\n",
      "(531358, 0, 'is not', 0)\n",
      "(611242, 0, 'there are', 2)\n",
      "(139297, 1, 'to have', 1)\n",
      "(107110, 0, 'in a', 0)\n",
      "(726767, 1, 'of the', 0)\n",
      "(168058, 1, 'in the', 0)\n",
      "(686086, 1, 'may have', 1)\n",
      "(871002, 1, 'this is', 1)\n",
      "(712044, 3, 'away from', 2)\n",
      "(879200, 1, 'a little', 1)\n",
      "(341642, 2, 'had to', 0)\n",
      "(200068, 1, 'may be', 0)\n",
      "(784446, 2, 'it was', 0)\n",
      "(69556, 1, 'they are', 1)\n",
      "Accuracy with 100 examples: 0.29. Expected acc: 0.286532951289\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    saver = tf.train.Saver() \n",
    "    saver.restore(session, '/home/rishubj/text/code/chkp/'+prefix+'model-final.chkp')\n",
    "    validate(session, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver = tf.train.Saver() \n",
    "        saver.restore(session, '/home/rishubj/text/code/chkp/'+prefix+'model-final.chkp')\n",
    "\n",
    "        return (tf.nn.embedding_lookup(embeddings, dictionary[word]).eval())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/rishubj/text/code/chkp/brown-steps-11000-model-final.chkp\n",
      "INFO:tensorflow:Restoring parameters from /home/rishubj/text/code/chkp/brown-steps-11000-model-final.chkp\n",
      "INFO:tensorflow:Restoring parameters from /home/rishubj/text/code/chkp/brown-steps-11000-model-final.chkp\n",
      "(1, 0, 84.48552, 0.36624822)\n",
      "(2, 0, 95.156586, 0.3921986)\n",
      "(2, 1, 76.2211, 0.45236146)\n"
     ]
    }
   ],
   "source": [
    "embs = list(map(get_word_embedding, ['reason', 'and', 'or']))\n",
    "def get_pair_diffs(embs):\n",
    "    for i,emb1 in enumerate(embs):\n",
    "        for j,emb2 in enumerate(embs):    \n",
    "            if i>j:\n",
    "                print (i,j,np.sum(np.square(emb1-emb2)), cos_sim(emb1, emb2))\n",
    "get_pair_diffs(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['going', 'to'], ['go', 'to'], ['get', 'the'], ['gt']]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[a for a in acc.split()] for acc in acro_dct['gt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 100.428406)\n",
      "(2, 0, 164.23688)\n",
      "(2, 1, 135.96286)\n",
      "(3, 0, 128.01617)\n",
      "(3, 1, 142.86218)\n",
      "(3, 2, 140.83066)\n",
      "(1, 0, 90.88211)\n",
      "(2, 0, 83.14571)\n",
      "(2, 1, 76.27577)\n",
      "(3, 0, 191.47186)\n",
      "(3, 1, 181.21515)\n",
      "(3, 2, 180.18509)\n",
      "('bw', ['but we', 'but when', 'but what', 'bw'], [191.47186, 181.21515, 180.18509, 0.0], [180.62204, 179.11804, 126.066635, 99.15965])\n",
      "(1, 0, 170.3965)\n",
      "(2, 0, 228.48177)\n",
      "(2, 1, 175.42642)\n",
      "(3, 0, 163.83879)\n",
      "(3, 1, 159.65094)\n",
      "(3, 2, 74.80139)\n",
      "('no', ['number of', 'not only', 'no one', 'no'], [163.83879, 159.65094, 74.80139, 0.0], [145.78696, 132.2341, 120.271866, 90.271454])\n",
      "(1, 0, 97.00676)\n",
      "(2, 0, 95.85985)\n",
      "(2, 1, 99.26204)\n",
      "(3, 0, 186.80972)\n",
      "(3, 1, 179.56418)\n",
      "(3, 2, 166.32327)\n",
      "('ys', ['you say', 'you see', 'you should', 'ys'], [186.80972, 179.56418, 166.32327, 0.0], [155.16168, 168.66434, 121.833176, 95.63918])\n",
      "(1, 0, 85.770096)\n",
      "(2, 0, 85.939545)\n",
      "(2, 1, 96.87598)\n",
      "('sy', ['said you', 'so you', 'see you'], [178.76996, 192.42989, 172.64941], [184.19571, 200.49649, 127.98596, 95.236084])\n",
      "(1, 0, 143.82889)\n",
      "(2, 0, 160.48412)\n",
      "(2, 1, 94.608154)\n",
      "(3, 0, 141.66586)\n",
      "(3, 1, 160.06517)\n",
      "(3, 2, 148.75)\n",
      "('ab', ['and by', 'a big', 'a bit', 'ab'], [141.66586, 160.06517, 148.75, 0.0], [158.37042, 156.40051, 132.04521, 89.689545])\n",
      "(1, 0, 213.3609)\n",
      "(2, 0, 196.67581)\n",
      "(2, 1, 231.03189)\n",
      "(3, 0, 174.5254)\n",
      "(3, 1, 194.99393)\n",
      "(3, 2, 159.09576)\n",
      "('sl', ['so long', 'st louis', 'she looked', 'sl'], [174.5254, 194.99393, 159.09576, 0.0], [166.53311, 166.95694, 145.5227, 94.74487])\n",
      "(1, 0, 91.52324)\n",
      "(2, 0, 113.2923)\n",
      "(2, 1, 104.64928)\n",
      "(3, 0, 164.73073)\n",
      "(3, 1, 152.62363)\n",
      "(3, 2, 151.34685)\n",
      "('co', ['center of', 'cost of', 'couple of', 'co'], [164.73073, 152.62363, 151.34685, 0.0], [160.56775, 164.88281, 143.64197, 87.20426])\n",
      "(1, 0, 86.42021)\n",
      "(2, 0, 209.32259)\n",
      "(2, 1, 195.6839)\n",
      "(3, 0, 170.45728)\n",
      "(3, 1, 169.6463)\n",
      "(3, 2, 187.74547)\n",
      "('yc', ['you can', 'you could', 'york city', 'yc'], [170.45728, 169.6463, 187.74547, 0.0], [153.47574, 169.02335, 142.8245, 84.51492])\n",
      "(1, 0, 96.226364)\n",
      "(2, 0, 140.55501)\n",
      "(2, 1, 159.6705)\n",
      "(3, 0, 148.1459)\n",
      "(3, 1, 170.20914)\n",
      "(3, 2, 168.81305)\n",
      "('pi', ['place in', 'published in', 'put it', 'pi'], [148.1459, 170.20914, 168.81305, 0.0], [160.53882, 172.57187, 127.92604, 88.60292])\n",
      "(1, 0, 60.300053)\n",
      "(2, 0, 84.15976)\n",
      "(2, 1, 83.73741)\n",
      "(3, 0, 105.66901)\n",
      "(3, 1, 104.09418)\n",
      "(3, 2, 109.507355)\n",
      "('it', ['in the', 'is the', 'into the', 'it'], [105.66901, 104.09418, 109.507355, 0.0], [144.92258, 147.83472, 104.015594, 84.50544])\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "baseline_embs = [sum([get_word_embedding(a) for a in acc.split()]) for acc in acro_dct['gt']]\n",
    "get_pair_diffs(baseline_embs)\n",
    "chosen_keys = np.random.choice(acro_dct.keys(), 10, replace=False)\n",
    "\n",
    "for i,key in enumerate(chosen_keys):\n",
    "    key_emb = get_word_embedding(key)\n",
    "    avg_acro_emb = [sum([get_word_embedding(a) for a in acc.split()]) for acc in acro_dct[key]]\n",
    "    diffs = [np.sum(np.square(emb1-key_emb)) for emb1 in avg_acro_emb]\n",
    "    baseline_diffs = [np.sum(np.square(emb1-key_emb)) for emb1 in baseline_embs]\n",
    "    get_pair_diffs(avg_acro_emb)\n",
    "    print(key, acro_dct[key], diffs, baseline_diffs)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 100.428406, 0.72483337)\n",
      "(2, 0, 164.23688, 0.4909631)\n",
      "(2, 1, 135.96286, 0.6024802)\n",
      "(3, 0, 128.01617, 0.52057517)\n",
      "(3, 1, 142.86218, 0.5045385)\n",
      "(3, 2, 140.83066, 0.3649831)\n",
      "(1, 0, 165.18912, 0.542567)\n",
      "(2, 0, 167.8566, 0.5532598)\n",
      "(2, 1, 88.34346, 0.73700744)\n",
      "('ho', ['his own', 'half of', 'history of'], [(185.74353, 0.3377572), (140.80896, 0.40280277), (143.83365, 0.44798553)], [(161.19272, 0.35740247), (151.83081, 0.46114996), (127.732185, 0.42679214), (88.57642, 0.29142246)])\n",
      "(1, 0, 101.60777, 0.73538816)\n",
      "(2, 0, 176.60388, 0.51117)\n",
      "(2, 1, 178.80844, 0.49976194)\n",
      "('ik', ['i know', 'i knew', 'is known'], [(179.6099, 0.3514278), (190.56964, 0.28914672), (158.20474, 0.35072473)], [(154.98935, 0.3932453), (161.11703, 0.42219943), (142.1923, 0.35866496), (92.191025, 0.28197667)])\n",
      "(1, 0, 189.49849, 0.51818293)\n",
      "(2, 0, 86.42021, 0.7740331)\n",
      "(2, 1, 184.56628, 0.5335789)\n",
      "('wc', ['we can', 'was called', 'we could'], [(168.34698, 0.3926527), (173.28806, 0.414851), (176.85315, 0.363563)], [(167.83661, 0.3379951), (175.96744, 0.35960057), (139.04803, 0.38046354), (91.37524, 0.3024262)])\n",
      "(1, 0, 190.30605, 0.5056926)\n",
      "(2, 0, 176.38956, 0.5289888)\n",
      "(2, 1, 98.34608, 0.7460361)\n",
      "(3, 0, 156.65558, 0.423076)\n",
      "(3, 1, 191.44748, 0.30651492)\n",
      "(3, 2, 180.7392, 0.31668726)\n",
      "('ym', ['you may', 'young man', 'young men', 'ym'], [(156.65558, 0.423076), (191.44748, 0.30651492), (180.7392, 0.31668726), (0.0, 1.0000001)], [(184.19492, 0.24158952), (184.80566, 0.30497813), (131.78491, 0.40268084), (96.57486, 0.2186154)])\n",
      "(1, 0, 164.14258, 0.58119184)\n",
      "(2, 0, 77.40164, 0.7892785)\n",
      "(2, 1, 76.74975, 0.80847126)\n",
      "('ao', ['and other', 'all of', 'and of'], [(149.2908, 0.44801247), (168.73344, 0.46074057), (144.65872, 0.492207)], [(142.79964, 0.45830926), (150.61499, 0.4750984), (123.45915, 0.46425843), (89.69163, 0.33283052)])\n",
      "(1, 0, 86.42021, 0.78349715)\n",
      "(2, 0, 209.32259, 0.45563346)\n",
      "(2, 1, 195.6839, 0.49398395)\n",
      "(3, 0, 170.45728, 0.4211746)\n",
      "(3, 1, 169.6463, 0.4308694)\n",
      "(3, 2, 187.74547, 0.30752084)\n",
      "('yc', ['you can', 'you could', 'york city', 'yc'], [(170.45728, 0.4211746), (169.6463, 0.4308694), (187.74547, 0.30752084), (0.0, 0.9999999)], [(153.47574, 0.41608042), (169.02335, 0.4012026), (142.8245, 0.37779224), (84.51492, 0.38923416)])\n",
      "(1, 0, 156.30423, 0.60352)\n",
      "(2, 0, 169.50204, 0.5694662)\n",
      "(2, 1, 85.51662, 0.7794066)\n",
      "(3, 0, 183.66571, 0.36305666)\n",
      "(3, 1, 192.05806, 0.30645737)\n",
      "(3, 2, 187.01529, 0.32643276)\n",
      "('hi', ['he is', 'him in', 'here in', 'hi'], [(183.66571, 0.36305666), (192.05806, 0.30645737), (187.01529, 0.32643276), (0.0, 1.0)], [(158.31662, 0.38541824), (153.37204, 0.4616075), (124.4642, 0.4568154), (95.00394, 0.28494522)])\n",
      "(1, 0, 133.46371, 0.5969326)\n",
      "(2, 0, 168.1648, 0.4971467)\n",
      "(2, 1, 84.75813, 0.7314691)\n",
      "('ea', ['even a', 'eyes and', 'economic and'], [(153.51207, 0.40777317), (142.44632, 0.3950278), (159.22827, 0.32768136)], [(149.47768, 0.42425695), (169.74373, 0.38838625), (130.17482, 0.42651793), (96.995186, 0.2639391)])\n",
      "(1, 0, 136.3758, 0.6239951)\n",
      "(2, 0, 151.74274, 0.5654858)\n",
      "(2, 1, 166.03087, 0.5544774)\n",
      "(3, 0, 131.05583, 0.5016058)\n",
      "(3, 1, 161.93575, 0.4389987)\n",
      "(3, 2, 154.80359, 0.43107378)\n",
      "('af', ['a few', 'and for', 'away from', 'af'], [(131.05583, 0.5016058), (161.93575, 0.4389987), (154.80359, 0.43107378), (0.0, 0.9999999)], [(135.47491, 0.49632093), (158.44427, 0.446815), (134.90424, 0.4173535), (86.528824, 0.3787251)])\n",
      "(1, 0, 85.733986, 0.7538869)\n",
      "(2, 0, 76.58848, 0.776334)\n",
      "(2, 1, 89.1492, 0.74062926)\n",
      "(3, 0, 132.28049, 0.5003805)\n",
      "(3, 1, 116.15364, 0.58002573)\n",
      "(3, 2, 121.25223, 0.5372036)\n",
      "('wt', ['with the', 'was the', 'when the', 'wt'], [(132.28049, 0.5003805), (116.15364, 0.58002573), (121.25223, 0.5372036), (0.0, 1.0)], [(137.12721, 0.47850865), (160.598, 0.42551988), (122.56608, 0.46053404), (81.47055, 0.36939615)])\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "baseline_embs = [sum([get_word_embedding(a) for a in acc.split()]) for acc in acro_dct['gt']]\n",
    "get_pair_diffs(baseline_embs)\n",
    "chosen_keys = np.random.choice(acro_dct.keys(), 10, replace=False)\n",
    "\n",
    "for i,key in enumerate(chosen_keys):\n",
    "    key_emb = get_word_embedding(key)\n",
    "    avg_acro_emb = [sum([get_word_embedding(a) for a in acc.split()]) for acc in acro_dct[key]]\n",
    "    diffs = [(np.sum(np.square(emb1-key_emb)), cos_sim(emb1, key_emb)) for emb1 in avg_acro_emb]\n",
    "    baseline_diffs = [(np.sum(np.square(emb1-key_emb)), cos_sim(emb1, key_emb)) for emb1 in baseline_embs]\n",
    "    get_pair_diffs(avg_acro_emb)\n",
    "    print(key, acro_dct[key], diffs, baseline_diffs)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prefix=''\n",
    "\n",
    "# with tf.Session(graph=graph) as session:\n",
    "#     saver = tf.train.Saver() \n",
    "#     saver.restore(session, '/home/rishubj/text/code/chkp/'+prefix+'model-final.chkp')\n",
    "#     feed_dict = {train_inputs: batch_inputs, train_context: batch_context}\n",
    "\n",
    "#     # We perform one update step by evaluating the optimizer op (including it\n",
    "#     # in the list of returned values for session.run()\n",
    "\n",
    "#     loss_val = session.run(nce_loss, feed_dict=feed_dict)\n",
    "#     average_loss += loss_val\n",
    "\n",
    "\n",
    "\n",
    "#     # Now, redo it for acronyms:\n",
    "#     data_word = acro_data[0]\n",
    "\n",
    "#     acro_batch_inputs = []\n",
    "#     acro_batch_context = []\n",
    "#     for single_acro_data in data_word:\n",
    "#         a,b = generate_batch_from_acro_data(single_acro_data,\n",
    "#                 acro_batch_size, skip_window)\n",
    "#         acro_batch_inputs.append(a)\n",
    "#         acro_batch_context.append(b)\n",
    "#     acro_feed_dict = {train_acro_inputs: acro_batch_inputs, train_acro_context: acro_batch_context}\n",
    "#     best_acro = session.run(best_acro_chosen, feed_dict=acro_feed_dict)\n",
    "#     print(best_acro, data_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
